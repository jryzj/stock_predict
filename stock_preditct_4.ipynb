{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stock_preditct_4.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "HD7sGnxvgEkL",
        "VwbHlvXUgjp-",
        "OM3cHJETg0om",
        "uhyvAKdihCrC",
        "JZusNrhchOaS",
        "WkqwirDJnxSs",
        "RIfx1kh8nkAq",
        "v7l4RbsFikd4",
        "x17JDv8Wi12w",
        "lUmQNnUyjYPO",
        "llpn-tNzjwO3",
        "uzFRlwZzkAfw",
        "bgdFoC0ZqnOx",
        "ycLBn2g9eJoz",
        "yMaIpUCXdKAd",
        "TtE3stnXDcz1",
        "cH6D_yy4Dc0K",
        "Jz7H77AjNK9p",
        "4ji2nW0xNK9-",
        "0n5kGdKdNK-L",
        "Nh9nRcdaNK-U",
        "XitBIfkFNK-d",
        "NeK-E3zCsBub",
        "QCpq_WYJsBux",
        "IOpu9aoFsBu-",
        "mFHZhz3NsBvU",
        "8WUuXH9nsBvj",
        "V1_k6_jXNQx6",
        "6qYIH7kzfsNh",
        "Vj_SJEQ_f2-h",
        "DyRaLilwhXDe",
        "51tkVCF26Agg",
        "LBQKvnNyvv76",
        "L7ibvQRGvv8G",
        "AQeHx4HBvv8O",
        "lJUabvmyvv8e",
        "NCk527zzvv85",
        "kKXBcctzvv95",
        "P8iDRzhCvv-S",
        "cKV8H5ywvv-m",
        "3TdN1QEEvv-5",
        "jo_Nwseevv_d",
        "V9ukse_8iNG1",
        "XqH6I3rXiNHC",
        "BN8mbQlliNHU",
        "szBLpsH5iNHt",
        "ASbuU208iNHz",
        "zkuQIxtaJ7jr"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jryzj/stock_predict/blob/master/stock_preditct_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhCsGpjYwSIn",
        "colab_type": "text"
      },
      "source": [
        "##Begin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwEQMN-Eeza0",
        "colab_type": "text"
      },
      "source": [
        "##mount google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNldvRWte7Q6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "753d1d9d-6865-4dd0-c355-6d329c517ae0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdriver')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdriver; to attempt to forcibly remount, call drive.mount(\"/content/gdriver\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pxq9oTrwWEX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "858228a1-b7c9-4f14-8860-4b2c9eaeba19"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Sep 18 10:26:07 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMkJNgh2VhLp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "ffa4ff18-35ea-445f-fdd8-d02c6d7bd66f"
      },
      "source": [
        "#for tensorflow2\n",
        "\n",
        "import sys\n",
        "sys.path\n",
        "sys.path[0]='/tensorflow-2.1.0/python3.6'\n",
        "sys.path"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/tensorflow-2.1.0/python3.6',\n",
              " '/env/python',\n",
              " '/usr/lib/python36.zip',\n",
              " '/usr/lib/python3.6',\n",
              " '/usr/lib/python3.6/lib-dynload',\n",
              " '/usr/local/lib/python3.6/dist-packages',\n",
              " '/usr/lib/python3/dist-packages',\n",
              " '/usr/local/lib/python3.6/dist-packages/IPython/extensions',\n",
              " '/root/.ipython']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkMcs1dkWG__",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "517cd77b-8f39-434a-cd6e-f58bbe5667d8"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__\n",
        "\n",
        "# tf.compat.v1.disable_eager_execution()\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GnFSbgvWbzH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d6124531-4730-45dc-82aa-b06e79f0cbd2"
      },
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6Yc7lCufBu2",
        "colab_type": "text"
      },
      "source": [
        "#change path to notebook in cloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lw16QijjfKWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.getcwd()\n",
        "# os.chdir(\"/../content/gdriver/My Drive/Colab Notebooks (1)\")\n",
        "os.chdir(\"/../content/gdriver/My Drive/Colab Notebooks\")\n",
        "\n",
        "# os.chdir(\"/../content/gdriver/My Drive\")\n",
        "# os.chdir(\"gdriver/My Drive/Colab Notebooks\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyT1uBAgFb2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZpj2K30fRlh",
        "colab_type": "text"
      },
      "source": [
        "#set constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ye2mvVArfUru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#常数设置\n",
        "\n",
        "threshold = 3.0 #涨幅\n",
        "start_date = \"2006-01-01\"\n",
        "end_date = \"2019-06-23\"\n",
        "stock_prefix = \"sh.6|sz.0|sz.300\"\n",
        "\n",
        "window_size = 90\n",
        "predict_window_size = 5\n",
        "# adjustflag = \"1\" #后复权\n",
        "adjustflag = \"3\" #不复权\n",
        "days_from_ipo = 20 #新股上市一般会连涨很多天，排除这些比较异常的天数\n",
        "\n",
        "data_fields = [\"open\", \"high\", \"low\", \"close\", \"turn\",\"pctChg\",\"tradestatus\",\"isST\",\"code\"]\n",
        "all_data_fields = \"date,code,open,high,low,close,preclose,volume,amount,adjustflag,turn,tradestatus,pctChg,isST\"\n",
        "\n",
        "\n",
        "# factor_num = len(data_fields) - 4 #pctChg, tradestatus, code isST不参与模型计算\n",
        "factor_num = 12\n",
        "\n",
        "all_stock_data = \"all_stock_data.csv\"\n",
        "all_stock_data_1 = \"all_stock_data_1.csv\"\n",
        "all_stock_data_2 = \"all_stock_data_2.csv\" #不复权\n",
        "all_stock_data_3 = \"all_stock_data_3.csv\" #with all data fields, no divid adjusting\n",
        "\n",
        "ts_code_file = \"ts_code.csv\"\n",
        "market_index = [\"sh.000001\", \"sz.399106\"]\n",
        "market_index_data_file = \"market_index_data.csv\"\n",
        "\n",
        "# predict_next_days = 1\n",
        "predict_next_days = 20"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4pkQsmZepWu",
        "colab_type": "text"
      },
      "source": [
        "#intall pack necessary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1OEz0tQfgFo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "95fdf4c0-d060-4ef9-85cc-2dc96d40f4f1"
      },
      "source": [
        "!pip install baostock\n",
        "import baostock as bs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting baostock\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/e2/b367c78db42bafcf752442b7d582ba2a724286313d9f126c5fee06064fb2/baostock-0.8.8-py3-none-any.whl (55kB)\n",
            "\r\u001b[K     |██████                          | 10kB 20.4MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 30kB 2.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 40kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 2.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from baostock) (1.0.5)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18.0->baostock) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18.0->baostock) (1.18.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18.0->baostock) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.18.0->baostock) (1.15.0)\n",
            "Installing collected packages: baostock\n",
            "Successfully installed baostock-0.8.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nveGeL_Mfl7K",
        "colab_type": "text"
      },
      "source": [
        "#import basic pack"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9pLaOARfpbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#引入基本包\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "# import baostock as bs\n",
        "import random\n",
        "import datetime\n",
        "\n",
        "import gc\n",
        "\n",
        "np.random.seed(2019)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVjGRTMSfvxZ",
        "colab_type": "text"
      },
      "source": [
        "#import keras pack"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm0RuSbhgDQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##for tensorflow2\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import initializers\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTrvFj1EQ3AQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "a86eab9e-a509-4a7e-c0c7-f0cec7d08cf0"
      },
      "source": [
        "!pip install --upgrade keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
            "\r\u001b[K     |▉                               | 10kB 26.9MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20kB 31.3MB/s eta 0:00:01\r\u001b[K     |██▋                             | 30kB 34.9MB/s eta 0:00:01\r\u001b[K     |███▌                            | 40kB 38.4MB/s eta 0:00:01\r\u001b[K     |████▍                           | 51kB 33.9MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 61kB 35.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 71kB 29.2MB/s eta 0:00:01\r\u001b[K     |███████                         | 81kB 29.2MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 92kB 31.1MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 102kB 27.2MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 112kB 27.2MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 122kB 27.2MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 133kB 27.2MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 143kB 27.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 153kB 27.2MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 163kB 27.2MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 174kB 27.2MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 184kB 27.2MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 194kB 27.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 204kB 27.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 215kB 27.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 225kB 27.2MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 235kB 27.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 245kB 27.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 256kB 27.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 266kB 27.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 276kB 27.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 286kB 27.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 296kB 27.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 307kB 27.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 317kB 27.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 327kB 27.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 337kB 27.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 348kB 27.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 358kB 27.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 368kB 27.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 378kB 27.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.2.5\n",
            "    Uninstalling Keras-2.2.5:\n",
            "      Successfully uninstalled Keras-2.2.5\n",
            "Successfully installed keras-2.3.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKa8wdFDCWee",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0e55f45c-8f24-43d0-b835-e5676282a824"
      },
      "source": [
        "print(keras.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HD7sGnxvgEkL",
        "colab_type": "text"
      },
      "source": [
        "#setup tensorboard if need"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3XacfEsgJjo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LOG_DIR = \"/content/gdriver/My\\ Drive/Colab\\ Notebooks/tensor_board/stock_predict_2\"\n",
        "LOG_DIR1 = \"/content/gdriver/My Drive/Colab Notebooks/tensor_board/stock_predict_2\"\n",
        "\n",
        "from keras.callbacks import TensorBoard\n",
        "tbCallBack = TensorBoard(log_dir= LOG_DIR1 , histogram_freq=1,\n",
        "#                          write_graph=True,\n",
        "                         write_grads=True,\n",
        "                         batch_size=batch_size,\n",
        "#                          write_images=True\n",
        "                        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXxNrLWKgX1m",
        "colab_type": "text"
      },
      "source": [
        "#setup ngrok if need"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwbHlvXUgjp-",
        "colab_type": "text"
      },
      "source": [
        "##install ngrok"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5GO9QfOgR_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OM3cHJETg0om",
        "colab_type": "text"
      },
      "source": [
        "##setup ngrok account"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Z7OQRlDgn0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!./ngrok authtoken 6wz1ai2QDnxrk1HYUor4U_4zjD6PD8wUkGyMnWnmXiQ\n",
        "# get_ipython().system_raw('./ngrok authtoken 6wz1ai2QDnxrk1HYUor4U_4zjD6PD8wUkGyMnWnmXiQ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhyvAKdihCrC",
        "colab_type": "text"
      },
      "source": [
        "##start ngrok service"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfjG1F1UhInS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#开启ngrok service，绑定port 6006(tensorboard)\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "# !./ngrok http 6006"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZusNrhchOaS",
        "colab_type": "text"
      },
      "source": [
        "##get ngrok website"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6V1nPulhmJs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! curl http://localhost:4040/api/tunnels | python3 -c \\\n",
        "\"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkqwirDJnxSs",
        "colab_type": "text"
      },
      "source": [
        "#get ts code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2dEYovPn1EZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#获取股票代码清单\n",
        "#### 登陆系统 ####\n",
        "lg = bs.login()\n",
        "# 显示登陆返回信息\n",
        "print('login respond error_code:'+lg.error_code)\n",
        "print('login respond  error_msg:'+lg.error_msg)\n",
        "\n",
        "#### 获取证券信息 ####\n",
        "rs = bs.query_all_stock(day=\"2019-06-28\")\n",
        "print('query_all_stock respond error_code:'+rs.error_code)\n",
        "print('query_all_stock respond  error_msg:'+rs.error_msg)\n",
        "\n",
        "#### 打印结果集 ####\n",
        "data_list = []\n",
        "while (rs.error_code == '0') & rs.next():\n",
        "    # 获取一条记录，将记录合并在一起\n",
        "    data_list.append(rs.get_row_data())\n",
        "ts_code = pd.DataFrame(data_list, columns=rs.fields)\n",
        "\n",
        "#### 结果集输出到csv文件 ####   \n",
        "# ts_code.to_csv(\"D:\\\\all_stock.csv\", encoding=\"gbk\", index=False)\n",
        "print(ts_code)\n",
        "\n",
        "#### 登出系统 ####\n",
        "bs.logout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIfx1kh8nkAq",
        "colab_type": "text"
      },
      "source": [
        "#get ts histroy data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SETWlt3InopO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ebafd0ed-126c-4fe0-abf6-f48ebbf75a34"
      },
      "source": [
        "#获取股票历史数据\n",
        "#用DataFrame.append的方法是需要重新分配内存，完成追加数据\n",
        "#先用list.append的方法是用指针指向追加数据，内存不重新分配，数据大的时候，效率高\n",
        "#每次获取一支股票的数据，追加到csv文件中。\n",
        "#不复权\n",
        "\n",
        "adjustflag = \"3\"  #不复权\n",
        "\n",
        "result = pd.DataFrame([],columns = all_data_fields.split(\",\"))\n",
        "result.to_csv(all_stock_data_3)\n",
        "\n",
        "bs.login()\n",
        "for i in range(len(ts_code)):\n",
        "    if i % 50 == 0:\n",
        "        print(i)\n",
        "    rs = bs.query_history_k_data_plus(ts_code.iloc[i][\"code\"], all_data_fields,\\\n",
        "                start_date = start_date, end_date = end_date,\\\n",
        "                  frequency = \"d\", adjustflag = adjustflag) #不复权\n",
        "\n",
        "    data_list = []\n",
        "    while (rs.error_code == \"0\") and rs.next():\n",
        "        row_data = rs.get_row_data()\n",
        "        # if(row_data[6] == \"1\"):    #  停牌的日子还是应该获取的。   \n",
        "        data_list.append(row_data)\n",
        "    result = pd.DataFrame(data_list, columns = rs.fields)\n",
        "    result.to_csv(all_stock_data_3, mode = \"a\", header=False)\n",
        "\n",
        "bs.logout()\n",
        "\n",
        "\n",
        "print(result.head())\n",
        "print(result.tail())\n",
        "print(result.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "login success!\n",
            "0\n",
            "50\n",
            "100\n",
            "150\n",
            "200\n",
            "250\n",
            "300\n",
            "350\n",
            "400\n",
            "450\n",
            "500\n",
            "550\n",
            "600\n",
            "650\n",
            "700\n",
            "750\n",
            "800\n",
            "850\n",
            "900\n",
            "950\n",
            "1000\n",
            "1050\n",
            "1100\n",
            "1150\n",
            "1200\n",
            "1250\n",
            "1300\n",
            "1350\n",
            "1400\n",
            "1450\n",
            "1500\n",
            "1550\n",
            "1600\n",
            "1650\n",
            "1700\n",
            "1750\n",
            "1800\n",
            "1850\n",
            "1900\n",
            "1950\n",
            "2000\n",
            "2050\n",
            "2100\n",
            "2150\n",
            "2200\n",
            "2250\n",
            "2300\n",
            "2350\n",
            "2400\n",
            "2450\n",
            "2500\n",
            "2550\n",
            "2600\n",
            "2650\n",
            "2700\n",
            "2750\n",
            "2800\n",
            "2850\n",
            "2900\n",
            "2950\n",
            "3000\n",
            "3050\n",
            "3100\n",
            "3150\n",
            "3200\n",
            "3250\n",
            "3300\n",
            "3350\n",
            "3400\n",
            "3450\n",
            "3500\n",
            "3550\n",
            "3600\n",
            "logout success!\n",
            "         date       code     open  ... tradestatus     pctChg isST\n",
            "0  2019-06-18  sz.300782  42.3500  ...           1  44.006800    0\n",
            "1  2019-06-19  sz.300782  55.9000  ...           1   9.996069    0\n",
            "2  2019-06-20  sz.300782  61.4900  ...           1  10.000000    0\n",
            "3  2019-06-21  sz.300782  67.6400  ...           1  10.001620    0\n",
            "\n",
            "[4 rows x 14 columns]\n",
            "         date       code     open  ... tradestatus     pctChg isST\n",
            "0  2019-06-18  sz.300782  42.3500  ...           1  44.006800    0\n",
            "1  2019-06-19  sz.300782  55.9000  ...           1   9.996069    0\n",
            "2  2019-06-20  sz.300782  61.4900  ...           1  10.000000    0\n",
            "3  2019-06-21  sz.300782  67.6400  ...           1  10.001620    0\n",
            "\n",
            "[4 rows x 14 columns]\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLnYyu6HqGbE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "db94b553-3099-4fe9-d09c-fd40efdc89cc"
      },
      "source": [
        "#\n",
        "\n",
        "adjustflag = \"3\"  #不复权\n",
        "\n",
        "result = pd.DataFrame([],columns = all_data_fields.split(\",\"))\n",
        "result.to_csv(market_index_data)\n",
        "\n",
        "bs.login()\n",
        "for i in range(len(market_index)):\n",
        "  print(market_index[i])\n",
        "  rs = bs.query_history_k_data_plus(market_index[i], all_data_fields,\\\n",
        "                start_date = start_date, end_date = end_date,\\\n",
        "                  frequency = \"d\", adjustflag = adjustflag) #不复权\n",
        "\n",
        "  data_list = []\n",
        "  while (rs.error_code == \"0\") and rs.next():\n",
        "      row_data = rs.get_row_data() \n",
        "      data_list.append(row_data)\n",
        "  result = pd.DataFrame(data_list, columns = rs.fields)\n",
        "  result.to_csv(market_index_data, mode = \"a\", header=False)\n",
        "\n",
        "bs.logout()\n",
        "\n",
        "\n",
        "print(result.head())\n",
        "print(result.tail())\n",
        "print(result.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "login success!\n",
            "sh.000001\n",
            "sz.399106\n",
            "logout success!\n",
            "         date       code      open  ... tradestatus    pctChg isST\n",
            "0  2006-01-04  sz.399106  278.9900  ...           1  1.696865    0\n",
            "1  2006-01-05  sz.399106  283.8000  ...           1  1.993084    0\n",
            "2  2006-01-06  sz.399106  289.5700  ...           1  0.747070    0\n",
            "3  2006-01-09  sz.399106  291.4800  ...           1  1.023029    0\n",
            "4  2006-01-10  sz.399106  294.1500  ...           1  0.584498    0\n",
            "\n",
            "[5 rows x 14 columns]\n",
            "            date       code       open  ... tradestatus     pctChg isST\n",
            "3268  2019-06-17  sz.399106  1504.2410  ...           1  -0.195000    0\n",
            "3269  2019-06-18  sz.399106  1502.9070  ...           1   0.162700    0\n",
            "3270  2019-06-19  sz.399106  1542.4600  ...           1   1.475500    0\n",
            "3271  2019-06-20  sz.399106  1525.5030  ...           1   1.953800    0\n",
            "3272  2019-06-21  sz.399106  1567.0710  ...           1   1.339000    0\n",
            "\n",
            "[5 rows x 14 columns]\n",
            "3273\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJZpV7D7ht8X",
        "colab_type": "text"
      },
      "source": [
        "#load stock data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJrO2bDihxV1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "outputId": "1e049441-6f47-483c-e46e-2aabd24ef06c"
      },
      "source": [
        "ts_data = pd.read_csv(all_stock_data_3)\n",
        "print(ts_data.head())\n",
        "print(ts_data.tail())\n",
        "\n",
        "ts_code = pd.read_csv(ts_code_file)\n",
        "print(ts_code.head())\n",
        "\n",
        "market_index_data = pd.read_csv(market_index_data_file)\n",
        "print(market_index_data.head())\n",
        "print(market_index_data.tail())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Unnamed: 0        date       code  ...  tradestatus    pctChg  isST\n",
            "0           0  2006-01-04  sh.600000  ...            1  5.128205     0\n",
            "1           1  2006-01-05  sh.600000  ...            1  1.658537     0\n",
            "2           2  2006-01-06  sh.600000  ...            1  2.879081     0\n",
            "3           3  2006-01-09  sh.600000  ...            1 -1.212688     0\n",
            "4           4  2006-01-10  sh.600000  ...            1  0.283284     0\n",
            "\n",
            "[5 rows x 15 columns]\n",
            "         Unnamed: 0        date       code  ...  tradestatus     pctChg  isST\n",
            "7592154          10  2019-06-21  sz.300781  ...            1   3.825693     0\n",
            "7592155           0  2019-06-18  sz.300782  ...            1  44.006800     0\n",
            "7592156           1  2019-06-19  sz.300782  ...            1   9.996069     0\n",
            "7592157           2  2019-06-20  sz.300782  ...            1  10.000000     0\n",
            "7592158           3  2019-06-21  sz.300782  ...            1  10.001620     0\n",
            "\n",
            "[5 rows x 15 columns]\n",
            "   Unnamed: 0       code code_name\n",
            "0           0  sh.600000      浦发银行\n",
            "1           1  sh.600004      白云机场\n",
            "2           2  sh.600006      东风汽车\n",
            "3           3  sh.600007      中国国贸\n",
            "4           4  sh.600008      首创股份\n",
            "   Unnamed: 0        date       code  ...  tradestatus    pctChg  isST\n",
            "0           0  2006-01-04  sh.000001  ...            1  1.714473   0.0\n",
            "1           1  2006-01-05  sh.000001  ...            1  1.380740   0.0\n",
            "2           2  2006-01-06  sh.000001  ...            1  1.015056   0.0\n",
            "3           3  2006-01-09  sh.000001  ...            1  0.516443   0.0\n",
            "4           4  2006-01-10  sh.000001  ...            1  0.407190   0.0\n",
            "\n",
            "[5 rows x 15 columns]\n",
            "      Unnamed: 0        date       code  ...  tradestatus  pctChg  isST\n",
            "6541        3268  2019-06-17  sz.399106  ...            1 -0.1950   0.0\n",
            "6542        3269  2019-06-18  sz.399106  ...            1  0.1627   0.0\n",
            "6543        3270  2019-06-19  sz.399106  ...            1  1.4755   0.0\n",
            "6544        3271  2019-06-20  sz.399106  ...            1  1.9538   0.0\n",
            "6545        3272  2019-06-21  sz.399106  ...            1  1.3390   0.0\n",
            "\n",
            "[5 rows x 15 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlNy3GK9cJFe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "e5a39fc0-6dd4-4d35-944f-39292d0ddce3"
      },
      "source": [
        "ts_code = pd.read_csv(ts_code_file)\n",
        "print(ts_code.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Unnamed: 0       code code_name\n",
            "0           0  sh.600000      浦发银行\n",
            "1           1  sh.600004      白云机场\n",
            "2           2  sh.600006      东风汽车\n",
            "3           3  sh.600007      中国国贸\n",
            "4           4  sh.600008      首创股份\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ST2PaXXb0Fp_",
        "colab_type": "text"
      },
      "source": [
        "#prepare dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eeF-RTo0OT_",
        "colab_type": "text"
      },
      "source": [
        "##define dataset generating function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NjqnYAcG_Ja",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normals(np_array):\n",
        "  max_price = np_array.max()\n",
        "  min_price = np_array.min()\n",
        "  scale = max_price - min_price\n",
        "  return (np_array - min_price)/scale"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kEmGkQd0D6N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def gntor_like(ts_data, ts_code, mark_index_data, pct_of_stock=0.05, edge=10.0,\\\n",
        "                    shuffle = 0, y_cate = 1):  \n",
        "\n",
        "  stock_qty = len(ts_code)\n",
        "\n",
        "  \n",
        "  if pct_of_stock != 1:\n",
        "    index = random.sample(range(0,stock_qty), int(stock_qty*pct_of_stock))\n",
        "    ts_code = ts_code[ts_code.index.isin(index)].code.values\n",
        "  else:\n",
        "    index = ts_code.code.values\n",
        "  \n",
        "  print(len(index))                   \n",
        "\n",
        "  x = []\n",
        "  y = []\n",
        "\n",
        "  for i in index:\n",
        "\n",
        "    stk_data = ts_data[ts_data[\"code\"] == i]\n",
        "    length = len(stk_data)\n",
        "    if ((length - days_from_ipo - predict_next_days) > window_size):\n",
        "      for l in range(days_from_ipo, length - window_size - predict_next_days):\n",
        "        ohlct = stk_data.iloc[l : l + window_size + predict_next_days]\\\n",
        "            [[\"open\", \"high\", \"low\", \"close\", \"tradestatus\", \"isST\", \"pctChg\"]].values.astype(\"float\")\n",
        "        if np.all(ohlct[:,5] != 1) and \\\n",
        "          np.all(ohlct[:,4] != 0) and \\\n",
        "        np.all(ohlct[:,6] >= -10.1) and \\\n",
        "        np.all(ohlct[:,6] <= 10.1) :\n",
        "          ohlct[:-predict_next_days,:4] = normals(ohlct[:-predict_next_days,:4])\n",
        "\n",
        "          date_range = stk_data.iloc[l : l + window_size + predict_next_days][\"date\"]\n",
        "\n",
        "          sh_index_data = market_index_data[(market_index_data[\"code\"] == market_index[0])\\\n",
        "           & (market_index_data[\"date\"].isin(date_range))]\n",
        "          sh_index_data = sh_index_data[:-predict_next_days][[\"open\", \"high\", \"low\", \"close\"]].values.astype(\"float\")\n",
        "          sh_index_data = normals(sh_index_data)\n",
        "\n",
        "\n",
        "          sz_index_data = market_index_data[(market_index_data[\"code\"] == market_index[1])\\\n",
        "           & (market_index_data[\"date\"].isin(date_range))]\n",
        "          sz_index_data = sz_index_data[:-predict_next_days][[\"open\", \"high\", \"low\", \"close\"]].values.astype(\"float\")\n",
        "          sz_index_data = normals(sz_index_data) \n",
        "\n",
        "          x.append(np.expand_dims(np.hstack((ohlct[:-predict_next_days,:4], sh_index_data, sz_index_data)), axis=-1))\n",
        "\n",
        "          # next_days_pctChg = ohlct[-predict_next_days:,-1].sum()  #wrong\n",
        "          next_days_pctChg = (ohlct[-1,3] - ohlct[-predict_next_days,3]) * 100 / ohlct[-predict_next_days,3]\n",
        "\n",
        "          if next_days_pctChg  <= -edge:\n",
        "            y.append(0)\n",
        "          elif next_days_pctChg  <= 0:\n",
        "            y.append(1)\n",
        "          elif next_days_pctChg <= edge:\n",
        "            y.append(2)\n",
        "          else:\n",
        "            y.append(3)\n",
        "\n",
        "  if len(x) > 0:\n",
        "    X = np.array(x)\n",
        "    y = np.array(y)\n",
        "\n",
        "    # upsample\n",
        "    # dis = district\n",
        "\n",
        "    dis_count, dis_edge = np.histogram(y, bins = 4, range=(0,3))\n",
        "\n",
        "    dis_count = dis_count + 1.0 #plus 1 to avoid devide by zero\n",
        "    dis_count_max = dis_count.max()\n",
        "\n",
        "    time = dis_count_max/dis_count\n",
        "\n",
        "    # time = time.astype(int)\n",
        "\n",
        "    # time_count = np.apply_along_axis((lambda d: time[d.astype(int)]), \\\n",
        "    #                                 0 , y)\n",
        "\n",
        "    # X = np.repeat(X, time_count, axis = 0)\n",
        "    # y = np.repeat(y, time_count, axis = 0)\n",
        "\n",
        "    # shuffle dataset\n",
        "    if shuffle:\n",
        "      length = X.shape[0]\n",
        "\n",
        "      r_index = np.arange(length)\n",
        "      np.random.shuffle(r_index)\n",
        "\n",
        "      X = X[r_index]\n",
        "      y = y[r_index]\n",
        "\n",
        "    # r_index = random.sample(range(0,length), int(length / 4))\n",
        "\n",
        "    # X = X[r_index]\n",
        "    # y = y[r_index]\n",
        "\n",
        "    if y_cate:\n",
        "      y = utils.to_categorical(y, num_classes=4)\n",
        "    return X, y, time\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqdiohvyhSe1",
        "colab_type": "text"
      },
      "source": [
        "##make dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czNCx7cYhYWx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "912805d5-ca62-4c41-f0eb-16d9d8ce619b"
      },
      "source": [
        "pct_of_stock = 1\n",
        "edge = 10.0\n",
        "\n",
        "X1, y1, cls_weight = gntor(result, ts_code[:10], market_index_data, pct_of_stock, edge, [], 1, 0)\n",
        "\n",
        "np.save(\"X-3-1-7-w1000.npy\", X1)\n",
        "np.save(\"y-3-1-7-w1000.npy\", y1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iYKSNjCGwLG",
        "colab_type": "text"
      },
      "source": [
        "##generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_lTbB-JGzzQ",
        "colab_type": "text"
      },
      "source": [
        "###G1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZv5MMkQG2MW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def G1(ts_data, ts_code, mark_index_data, market_index, pct_of_stock=0.05, edge=10.0,\\\n",
        "                    shuffle = 0, y_cate = 1, batch_size=256):  \n",
        "\n",
        "  stock_qty = len(ts_code)\n",
        "\n",
        "  while True:\n",
        "    if pct_of_stock != 1:\n",
        "      index = random.sample(range(0,stock_qty), int(stock_qty*pct_of_stock))\n",
        "      index = ts_code[ts_code.index.isin(index)].code.values\n",
        "    else:\n",
        "      index = ts_code.code.values\n",
        "    \n",
        "    print(len(index))                   \n",
        "\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    for i in index:\n",
        "      stk_data = ts_data[ts_data[\"code\"] == i]\n",
        "      length = len(stk_data)\n",
        "      if ((length - days_from_ipo - predict_next_days) > window_size):\n",
        "        for l in range(days_from_ipo, length - window_size - predict_next_days):\n",
        "          ohlct = stk_data.iloc[l : l + window_size + predict_next_days]\\\n",
        "              [[\"open\", \"high\", \"low\", \"close\", \"tradestatus\", \"isST\", \"pctChg\"]].values.astype(\"float\")\n",
        "          if np.all(ohlct[:,5] != 1) and \\\n",
        "            np.all(ohlct[:,4] != 0) and \\\n",
        "          np.all(ohlct[:,6] >= -10.1) and \\\n",
        "          np.all(ohlct[:,6] <= 10.1) :\n",
        "            ohlct[:-predict_next_days,:4] = normals(ohlct[:-predict_next_days,:4])\n",
        "\n",
        "            date_range = stk_data.iloc[l : l + window_size + predict_next_days][\"date\"]\n",
        "\n",
        "            sh_index_data = market_index_data[(market_index_data[\"code\"] == market_index[0])\\\n",
        "            & (market_index_data[\"date\"].isin(date_range))]\n",
        "            sh_index_data = sh_index_data[:-predict_next_days][[\"open\", \"high\", \"low\", \"close\"]].values.astype(\"float\")\n",
        "            sh_index_data = normals(sh_index_data)\n",
        "\n",
        "\n",
        "            sz_index_data = market_index_data[(market_index_data[\"code\"] == market_index[1])\\\n",
        "            & (market_index_data[\"date\"].isin(date_range))]\n",
        "            sz_index_data = sz_index_data[:-predict_next_days][[\"open\", \"high\", \"low\", \"close\"]].values.astype(\"float\")\n",
        "            sz_index_data = normals(sz_index_data) \n",
        "\n",
        "            x.append(np.expand_dims(np.hstack((ohlct[:-predict_next_days,:4], sh_index_data, sz_index_data)), axis=-1))\n",
        "\n",
        "            # next_days_pctChg = ohlct[-predict_next_days:,-1].sum()  #wrong\n",
        "            next_days_pctChg = (ohlct[-1,3] - ohlct[-predict_next_days,3]) * 100 / ohlct[-predict_next_days,3]\n",
        "\n",
        "            if next_days_pctChg  <= -edge:\n",
        "              y.append(0)\n",
        "            elif next_days_pctChg  <= 0:\n",
        "              y.append(1)\n",
        "            elif next_days_pctChg <= edge:\n",
        "              y.append(2)\n",
        "            else:\n",
        "              y.append(3)\n",
        "\n",
        "    if len(x) > 0:\n",
        "      print(len(x))\n",
        "      X = np.array(x)\n",
        "      y = np.array(y)\n",
        "\n",
        "      # upsample\n",
        "      # dis = district\n",
        "\n",
        "      dis_count, dis_edge = np.histogram(y, bins = 4, range=(0,3))\n",
        "\n",
        "      dis_count = dis_count + 1.0 #plus 1 to avoid devide by zero\n",
        "      dis_count_min = dis_count.min()\n",
        "\n",
        "      time = dis_count_min/dis_count\n",
        "      sample_weight = np.array(y)\n",
        "      sample_weight[sample_weight == 0] = time[0]\n",
        "      sample_weight[sample_weight == 1] = time[1]\n",
        "      sample_weight[sample_weight == 2] = time[2]\n",
        "      sample_weight[sample_weight == 3] = time[3]\n",
        "\n",
        "\n",
        "      # time = time.astype(int)\n",
        "\n",
        "      # time_count = np.apply_along_axis((lambda d: time[d.astype(int)]), \\\n",
        "      #                                 0 , y)\n",
        "\n",
        "      # X = np.repeat(X, time_count, axis = 0)\n",
        "      # y = np.repeat(y, time_count, axis = 0)\n",
        "\n",
        "      # shuffle dataset\n",
        "      if shuffle:\n",
        "        length = X.shape[0]\n",
        "\n",
        "        r_index = np.arange(length)\n",
        "        np.random.shuffle(r_index)\n",
        "\n",
        "        X = X[r_index]\n",
        "        y = y[r_index]\n",
        "\n",
        "      # r_index = random.sample(range(0,length), int(length / 4))\n",
        "\n",
        "      # X = X[r_index]\n",
        "      # y = y[r_index]\n",
        "\n",
        "      if y_cate:\n",
        "        y = utils.to_categorical(y, num_classes=4)\n",
        "      \n",
        "      for i in range(0, y.shape[0], batch_size):\n",
        "        yield (X[i : i + batch_size], y[i : i + batch_size]\\\n",
        "               , sample_weight[i : i + batch_size]\\\n",
        "               )\n",
        "        \n",
        "        \n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeVRSkylh3Ve",
        "colab_type": "text"
      },
      "source": [
        "#test model are at below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQNsLIzGjMhB",
        "colab_type": "text"
      },
      "source": [
        "##Model 4-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWVVNt95jbHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_model(summary = False):\n",
        "  K.clear_session()\n",
        "  # tf.keras.backend.clear_session()\n",
        "  p_lstm = 64\n",
        "\n",
        "  input = layers.Input(shape = (window_size, factor_num, 1))\n",
        "\n",
        "\n",
        "  model_1 = layers.Conv2D(64, kernel_size =(1,4))(input)\n",
        "  model_1 = layers.Activation(\"relu\")(model_1)\n",
        "  model_1 = layers.BatchNormalization()(model_1)\n",
        "  model_1 = layers.Dropout(0.5)(model_1)\n",
        "\n",
        "  model_1 = layers.Reshape((-1,64))(model_1)\n",
        "\n",
        "  model_1 = layers.LSTM(p_lstm)(model_1)\n",
        "\n",
        "\n",
        "\n",
        "  model_5 = layers.Conv2D(128, kernel_size =(5,4))(input)\n",
        "  model_5 = layers.Activation(\"relu\")(model_5)\n",
        "  model_5 = layers.BatchNormalization()(model_5)\n",
        "  model_5 = layers.Dropout(0.5)(model_5)\n",
        "\n",
        "  model_5 = layers.Reshape((-1,128))(model_5)\n",
        "\n",
        "  model_5 = layers.LSTM(p_lstm)(model_5)\n",
        "\n",
        "  model_10 = layers.Conv2D(256, kernel_size =(10,4))(input)\n",
        "  model_10 = layers.Activation(\"relu\")(model_10)\n",
        "  model_10 = layers.BatchNormalization()(model_10)\n",
        "  model_10 = layers.Dropout(0.5)(model_10)\n",
        "\n",
        "  model_10 = layers.Reshape((-1,256))(model_10)\n",
        "\n",
        "  model_10 = layers.LSTM(p_lstm)(model_10)\n",
        "\n",
        "  model_20 = layers.Conv2D(512, kernel_size =(20,4))(input)\n",
        "  model_20 = layers.Activation(\"relu\")(model_20)\n",
        "  model_20 = layers.BatchNormalization()(model_20)\n",
        "  model_20 = layers.Dropout(0.5)(model_20)\n",
        "\n",
        "  model_20 = layers.Reshape((-1,512))(model_20)\n",
        "\n",
        "  model_20 = layers.LSTM(p_lstm)(model_20)\n",
        "\n",
        "\n",
        "\n",
        "  model_30 = layers.Conv2D(1024, kernel_size =(30,4))(input)\n",
        "  model_30 = layers.Activation(\"relu\")(model_30)\n",
        "  model_30 = layers.BatchNormalization()(model_30)\n",
        "  model_30 = layers.Dropout(0.5)(model_30)\n",
        "\n",
        "  model_30 = layers.Reshape((-1,1024))(model_30)\n",
        "\n",
        "  model_30 = layers.LSTM(p_lstm)(model_30)\n",
        "\n",
        "\n",
        "\n",
        "  model = layers.concatenate([model_1, model_5, model_10, model_20, model_30], axis = -1)\n",
        "\n",
        "\n",
        "  model = layers.Dense(2048)(model)\n",
        "  model = layers.Activation(\"relu\")(model)\n",
        "  model = layers.BatchNormalization()(model)\n",
        "  model = layers.Dropout(0.5)(model)\n",
        "\n",
        "\n",
        "  model = layers.Dense(1024)(model)\n",
        "  model = layers.Activation(\"relu\")(model)\n",
        "  model = layers.BatchNormalization()(model)\n",
        "  model = layers.Dropout(0.5)(model)\n",
        "\n",
        "  model = layers.Dense(512)(model)\n",
        "  model = layers.Activation(\"relu\")(model)\n",
        "  model = layers.BatchNormalization()(model)\n",
        "  model = layers.Dropout(0.5)(model)\n",
        "\n",
        "  model = layers.Dense(256)(model)\n",
        "  model = layers.Activation(\"relu\")(model)\n",
        "  model = layers.BatchNormalization()(model)\n",
        "  model = layers.Dropout(0.5)(model)\n",
        "\n",
        "  model = layers.Dense(128)(model)\n",
        "  model = layers.Activation(\"relu\")(model)\n",
        "  model = layers.BatchNormalization()(model)\n",
        "  model = layers.Dropout(0.5)(model)\n",
        "\n",
        "  model = layers.Dense(64)(model)\n",
        "  model = layers.Activation(\"relu\")(model)\n",
        "  model = layers.BatchNormalization()(model)\n",
        "  model = layers.Dropout(0.5)(model)\n",
        "\n",
        "  model = layers.Dense(32)(model)\n",
        "  model = layers.Activation(\"relu\")(model)\n",
        "  model = layers.BatchNormalization()(model)\n",
        "  model = layers.Dropout(0.5)(model)\n",
        "\n",
        "  model = layers.Dense(4)(model)\n",
        "  model = layers.Activation(\"softmax\")(model)\n",
        "\n",
        "  model = Model(inputs = input, outputs = model)\n",
        "\n",
        "  # opt = optimizers.RMSprop(lr = 0.0005, decay = 0.001)\n",
        "  opt = optimizers.Adam(lr = 0.0005, decay = 0.001)\n",
        "\n",
        "  model.compile(loss = \"categorical_crossentropy\", optimizer = opt, metrics = [\"acc\"])\n",
        "\n",
        "  if summary:\n",
        "    model.summary()\n",
        "\n",
        "  return model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4ngNCbgjo-K",
        "colab_type": "text"
      },
      "source": [
        "###training 4-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTiHoClHj1QF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 256"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FegrRqvTkDTm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "86574e99-dde0-4f53-87f2-8eed96781049"
      },
      "source": [
        "chk_point = ModelCheckpoint(filepath='stock_predict_4-1-set.h5')\n",
        "\n",
        "for i in range(8):\n",
        "\n",
        "  print(datetime.datetime.today())\n",
        "  model = make_model()\n",
        "  # model.load_weights(\"stock_predict_4-1-set.h5\") \n",
        "  for l in range(2):\n",
        "    model.fit(G1(ts_data, ts_code, market_index_data, market_index,\\\n",
        "                    pct_of_stock=0.005, edge=10.0,\\\n",
        "                    shuffle = 0, y_cate = 1, batch_size=batch_size),\\\n",
        "                    steps_per_epoch = batch_size,\\\n",
        "                    epochs = 10,\\\n",
        "                    callbacks = [chk_point],\\\n",
        "                    # validation_data = G1(ts_data, ts_code, mark_index_data, pct_of_stock=0.1, edge=10.0,\\\n",
        "                    # shuffle = 0, y_cate = 1, batchsize=batch_size)\n",
        "                    )\n",
        "    # history = model.fit(X_t, y_t, batch_size = 1024, epochs = 20,\\\n",
        "    #             # validation_split = 0.1, shuffle = True, \\\n",
        "    #             class_weight = cls_weight,\\\n",
        "    #             validation_data = (X_v ,y_v),\\\n",
        "    #             # callbacks = [tbCallBack]\\\n",
        "    #             callbacks = [chk_point],\\\n",
        "    #             # initial_epoch = 5 \n",
        "    #             ) \n",
        "\n",
        "    model.save_weights(\"stock_predict_4-11-set.h5\")\n",
        "\n",
        "  model.save_weights(\"stock_predict_4-1-set_a.h5\")\n",
        "  del model\n",
        "  gc.collect()\n",
        "plt.plot(history.history[\"acc\"]) \n",
        "print(datetime.datetime.today())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-09-18 10:28:33.399448\n",
            "18\n",
            "13671\n",
            "Epoch 1/10\n",
            " 53/256 [=====>........................] - ETA: 1:28 - loss: 0.0000e+00 - acc: 0.251818\n",
            " 54/256 [=====>........................] - ETA: 1:28 - loss: 0.0000e+00 - acc: 0.252416479\n",
            "118/256 [============>.................] - ETA: 4:07 - loss: 0.0000e+00 - acc: 0.253118\n",
            "119/256 [============>.................] - ETA: 4:04 - loss: 0.0000e+00 - acc: 0.2531"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxNoc_9giERB",
        "colab_type": "text"
      },
      "source": [
        "#Model 1: CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPFa4FEWkCFH",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7l4RbsFikd4",
        "colab_type": "text"
      },
      "source": [
        "##model 1-1: CNN + LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1lW5hjDiTBy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "bbc51a7d-70e2-4137-a1af-c16576ee1336"
      },
      "source": [
        "K.clear_session()\n",
        "\n",
        "input = layers.Input(shape = (window_size, factor_num - 2 ,1))\n",
        "\n",
        "model = layers.Conv2D(32, kernel_size = 4)(input)\n",
        "model = layers.Activation(\"relu\")(model)\n",
        "model = layers.BatchNormalization()(model)\n",
        "model = layers.Dropout(0.5)(model)\n",
        "\n",
        "model = layers.Reshape((-1, 32))(model)\n",
        "\n",
        "model = layers.Conv1D(32, kernel_size = 5)(model)\n",
        "model = layers.Activation(\"relu\")(model)\n",
        "model = layers.BatchNormalization()(model)\n",
        "model = layers.Dropout(0.5)(model)\n",
        "\n",
        "model = layers.Conv1D(64, kernel_size = 5)(model)\n",
        "model = layers.Activation(\"relu\")(model)\n",
        "model = layers.BatchNormalization()(model)\n",
        "model = layers.Dropout(0.5)(model)\n",
        "\n",
        "model = layers.Conv1D(256, kernel_size = 5)(model)\n",
        "model = layers.Activation(\"relu\")(model)\n",
        "model = layers.BatchNormalization()(model)\n",
        "model = layers.Dropout(0.5)(model)\n",
        "\n",
        "model = layers.Conv1D(512, kernel_size = 5)(model)\n",
        "model = layers.Activation(\"relu\")(model)\n",
        "model = layers.BatchNormalization()(model)\n",
        "model = layers.Dropout(0.5)(model)\n",
        "\n",
        "model = layers.LSTM(64)(model)\n",
        "model = layers.Activation(\"relu\")(model)\n",
        "model = layers.BatchNormalization()(model)\n",
        "model = layers.Dropout(0.5)(model)\n",
        "\n",
        "model = layers.Dense(32)(model)\n",
        "model = layers.Activation(\"relu\")(model)\n",
        "model = layers.BatchNormalization()(model)\n",
        "model = layers.Dropout(0.5)(model)\n",
        "\n",
        "model = layers.Dense(1)(model)\n",
        "\n",
        "model = Model(inputs = input, outputs = model)\n",
        "\n",
        "opt = optimizers.RMSprop(lr = 0.001, decay = 0.001)\n",
        "\n",
        "model.compile(loss = \"mse\", optimizer = opt)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-965e3ecc17cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor_num\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'K' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x17JDv8Wi12w",
        "colab_type": "text"
      },
      "source": [
        "###dataset 1-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvM6qL0EiQln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "pct_of_stock  = 0.004\n",
        "stock_qty = len(ts_code)\n",
        "\n",
        "index = random.sample(range(0,stock_qty), int(stock_qty*pct_of_stock))\n",
        "\n",
        "print(np.sort(index))\n",
        "                      \n",
        "x = []\n",
        "y = []\n",
        "\n",
        "for i in index:\n",
        "  stk_data = result[result.code == ts_code.iloc[i][\"code\"]]\n",
        "  length = len(stk_data)\n",
        "  if ((length - days_from_ipo - predict_next_days) > window_size):\n",
        "    for l in range(days_from_ipo, length - window_size - predict_next_days):\n",
        "      ohlct = stk_data.iloc[l : l + window_size + predict_next_days]\\\n",
        "          [[\"open\", \"high\", \"low\", \"close\", \"isST\", \"pctChg\"]].values\n",
        "      if np.all(ohlct[:, -2] != 1) and \\\n",
        "       np.all(ohlct[:,-1] > -10.0) and \\\n",
        "       np.all(ohlct[:,-1] < 10.0) :\n",
        "        max_price = ohlct[:-1,:-2].max()\n",
        "        min_price = ohlct[:-1,:-2].min()\n",
        "        scale = max_price - min_price\n",
        "        ohlct[:-1,:-2] = ([ohlct[:-1,:-2] - min_price]) /scale\n",
        "\n",
        "        x.extend([np.expand_dims(ohlct[:-predict_next_days,:-2], axis=-1)])\n",
        "\n",
        "        # y.extend([utils.to_categorical(ohlct[-1,-1], num_classes=201)])\n",
        "        ohlct[-1,-1] = (ohlct[-1,-1] + 10.0) / 20.0\n",
        "        y.extend([ohlct[-1,-1]])\n",
        "\n",
        "\n",
        "\n",
        "X = np.array(x)\n",
        "y = np.array(y)\n",
        "\n",
        "\n",
        "# upsample\n",
        "# dis = district\n",
        "dis_count, dis_edge = np.histogram(y, bins = 20)\n",
        "\n",
        "dis_count_max = dis_count.max() * 4\n",
        "\n",
        "dis_count = dis_count_max/dis_count\n",
        "dis_count = dis_count.astype(int)\n",
        "\n",
        "time_count = np.apply_along_axis((lambda d: dis_count[(d*100//5).astype(int)]), \\\n",
        "                                0 , y)\n",
        "\n",
        "X = np.repeat(X, time_count, axis = 0)\n",
        "y = np.repeat(y, time_count, axis = 0)\n",
        "\n",
        "length = X.shape[0]\n",
        "\n",
        "index = np.arange(length)\n",
        "np.random.shuffle(index)\n",
        "\n",
        "X = X[index]\n",
        "y = y[index]\n",
        "\n",
        "index = random.sample(range(0,length), int(length / 4))\n",
        "\n",
        "X = X[index]\n",
        "y = y[index]\n",
        "\n",
        "print(X.shape)\n",
        "print(X[1])\n",
        "print(y[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUmQNnUyjYPO",
        "colab_type": "text"
      },
      "source": [
        "###draw data distribution 1-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDQEhrWGjW0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(y, bins = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llpn-tNzjwO3",
        "colab_type": "text"
      },
      "source": [
        "###training 1-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QIWpgbdj797",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.load_weights(\"stock_predict_3_1-1.h5\")\n",
        "\n",
        "history = model.fit(X, y, batch_size = 1024, epochs = 240,\\\n",
        "            validation_split = 0.1, shuffle = True, \\\n",
        "            # callbacks = [tbCallBack]\\\n",
        "            )\n",
        "# plt.plot(history.history[\"acc\"])\n",
        "plt.plot(history.history[\"loss\"])\n",
        "model.save_weights(\"stock_predict_3_1-1.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzFRlwZzkAfw",
        "colab_type": "text"
      },
      "source": [
        "###drawing validation 1-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v9SqPo8kIxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.load_weights(\"stock_predict_3_1-1.h5\")\n",
        "\n",
        "history = model.fit(X, y, batch_size = 1024, epochs = 240,\\\n",
        "            validation_split = 0.1, shuffle = True, \\\n",
        "            # callbacks = [tbCallBack]\\\n",
        "            )\n",
        "# plt.plot(history.history[\"acc\"])\n",
        "plt.plot(history.history[\"loss\"])\n",
        "model.save_weights(\"stock_predict_3_1-1.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLL6GnFjyQW-",
        "colab_type": "text"
      },
      "source": [
        "##model 1-2: CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCtdPQjVyEzG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "K.clear_session()\n",
        "\n",
        "input = layers.Input(shape = (window_size, factor_num - 1 ,1))\n",
        "\n",
        "\n",
        "model_1 = layers.Conv2D(32, kernel_size =(1,4))(input)\n",
        "model_1 = layers.Activation(\"relu\")(model_1)\n",
        "model_1 = layers.BatchNormalization()(model_1)\n",
        "model_1 = layers.Dropout(0.5)(model_1)\n",
        "\n",
        "model_1 = layers.Reshape((-1, 32))(model_1)\n",
        "\n",
        "# model_1 = layers.Conv1D(32, kernel_size = 5)(model_1)\n",
        "# model_1 = layers.Activation(\"relu\")(model_1)\n",
        "# model_1 = layers.BatchNormalization()(model_1)\n",
        "# model_1 = layers.Dropout(0.5)(model_1)\n",
        "\n",
        "# model_1 = layers.Conv1D(64, kernel_size = 5)(model_1)\n",
        "# model_1 = layers.Activation(\"relu\")(model_1)\n",
        "# model_1 = layers.BatchNormalization()(model_1)\n",
        "# model_1 = layers.Dropout(0.5)(model_1)\n",
        "\n",
        "# model_1 = layers.Conv1D(128, kernel_size = 5)(model_1)\n",
        "# model_1 = layers.Activation(\"relu\")(model_1)\n",
        "# model_1 = layers.BatchNormalization()(model_1)\n",
        "# model_1 = layers.Dropout(0.5)(model_1)\n",
        "\n",
        "\n",
        "model_5 = layers.Conv2D(32, kernel_size =(5,4))(input)\n",
        "model_5 = layers.Activation(\"relu\")(model_5)\n",
        "model_5 = layers.BatchNormalization()(model_5)\n",
        "model_5 = layers.Dropout(0.5)(model_5)\n",
        "\n",
        "model_5 = layers.Reshape((-1, 32))(model_5)\n",
        "\n",
        "# model_5 = layers.Conv1D(64, kernel_size = 5)(model_5)\n",
        "# model_5 = layers.Activation(\"relu\")(model_5)\n",
        "# model_5 = layers.BatchNormalization()(model_5)\n",
        "# model_5 = layers.Dropout(0.5)(model_5)\n",
        "\n",
        "# model_5 = layers.Conv1D(128, kernel_size = 5)(model_5)\n",
        "# model_5 = layers.Activation(\"relu\")(model_5)\n",
        "# model_5 = layers.BatchNormalization()(model_5)\n",
        "# model_5 = layers.Dropout(0.5)(model_5)\n",
        "\n",
        "# model_5 = layers.Conv1D(256, kernel_size = 5)(model_5)\n",
        "# model_5 = layers.Activation(\"relu\")(model_5)\n",
        "# model_5 = layers.BatchNormalization()(model_5)\n",
        "# model_5 = layers.Dropout(0.5)(model_5)\n",
        "\n",
        "\n",
        "model_20 = layers.Conv2D(32, kernel_size =(20,4))(input)\n",
        "model_20 = layers.Activation(\"relu\")(model_20)\n",
        "model_20 = layers.BatchNormalization()(model_20)\n",
        "model_20 = layers.Dropout(0.5)(model_20)\n",
        "\n",
        "model_20 = layers.Reshape((-1, 32))(model_20)\n",
        "\n",
        "# model_20 = layers.Conv1D(64, kernel_size = 20)(model_20)\n",
        "# model_20 = layers.Activation(\"relu\")(model_20)\n",
        "# model_20 = layers.BatchNormalization()(model_20)\n",
        "# model_20 = layers.Dropout(0.5)(model_20)\n",
        "\n",
        "# model_20 = layers.Conv1D(128, kernel_size = 20)(model_20)\n",
        "# model_20 = layers.Activation(\"relu\")(model_20)\n",
        "# model_20 = layers.BatchNormalization()(model_20)\n",
        "# model_20 = layers.Dropout(0.5)(model_20)\n",
        "\n",
        "# model_20 = layers.Conv1D(256, kernel_size = 20)(model_20)\n",
        "# model_20 = layers.Activation(\"relu\")(model_20)\n",
        "# model_20 = layers.BatchNormalization()(model_20)\n",
        "# model_20 = layers.Dropout(0.5)(model_20)\n",
        "\n",
        "\n",
        "model_30 = layers.Conv2D(32, kernel_size =(30,4))(input)\n",
        "model_30 = layers.Activation(\"relu\")(model_30)\n",
        "model_30 = layers.BatchNormalization()(model_30)\n",
        "model_30 = layers.Dropout(0.5)(model_30)\n",
        "\n",
        "model_30 = layers.Reshape((-1, 32))(model_30)\n",
        "\n",
        "# model_30 = layers.Conv1D(64, kernel_size = 30)(model_30)\n",
        "# model_30 = layers.Activation(\"relu\")(model_30)\n",
        "# model_30 = layers.BatchNormalization()(model_30)\n",
        "# model_30 = layers.Dropout(0.5)(model_30)\n",
        "\n",
        "# # model_30 = layers.Conv1D(64, kernel_size = 30)(model_30)\n",
        "# # model_30 = layers.Activation(\"relu\")(model_30)\n",
        "# # model_30 = layers.BatchNormalization()(model_30)\n",
        "# # model_30 = layers.Dropout(0.5)(model_30)\n",
        "\n",
        "# model_30 = layers.Conv1D(256, kernel_size = 30)(model_30)\n",
        "# model_30 = layers.Activation(\"relu\")(model_30)\n",
        "# model_30 = layers.BatchNormalization()(model_30)\n",
        "# model_30 = layers.Dropout(0.5)(model_30)\n",
        "\n",
        "\n",
        "\n",
        "model = layers.concatenate([model_1, model_5, model_20, model_30], axis = -2)\n",
        "\n",
        "model = layers.Flatten()(model)\n",
        "\n",
        "model = layers.Dense(64)(model)\n",
        "model = layers.Activation(\"relu\")(model)\n",
        "model = layers.BatchNormalization()(model)\n",
        "model = layers.Dropout(0.5)(model)\n",
        "\n",
        "model = layers.Dense(32)(model)\n",
        "model = layers.Activation(\"relu\")(model)\n",
        "model = layers.BatchNormalization()(model)\n",
        "model = layers.Dropout(0.5)(model)\n",
        "\n",
        "model = layers.Dense(1)(model)\n",
        "\n",
        "model = Model(inputs = input, outputs = model)\n",
        "\n",
        "opt = optimizers.RMSprop(lr = 0.001, decay = 0.001)\n",
        "\n",
        "model.compile(loss = \"mse\", optimizer = opt)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aHbZzoodbpC",
        "colab_type": "text"
      },
      "source": [
        "###dataset 1-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAF9GL6Ydnas",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pct_of_stock  = 0.004\n",
        "stock_qty = len(ts_code)\n",
        "\n",
        "index = random.sample(range(0,stock_qty), int(stock_qty*pct_of_stock))\n",
        "\n",
        "print(np.sort(index))\n",
        "                      \n",
        "x = []\n",
        "y = []\n",
        "\n",
        "for i in index:\n",
        "  stk_data = result[result.code == ts_code.iloc[i][\"code\"]]\n",
        "  length = len(stk_data)\n",
        "  if ((length - days_from_ipo - predict_next_days) > window_size):\n",
        "    for l in range(days_from_ipo, length - window_size - predict_next_days):\n",
        "      ohlct = stk_data.iloc[l : l + window_size + predict_next_days]\\\n",
        "          [[\"open\", \"high\", \"low\", \"close\", \"isST\", \"pctChg\"]].values\n",
        "      if np.all(ohlct[:, -2] != 1) and \\\n",
        "       np.all(ohlct[:,-1] > -10.0) and \\\n",
        "       np.all(ohlct[:,-1] < 10.0) :\n",
        "        max_price = ohlct[:-predict_next_days,:-2].max()\n",
        "        min_price = ohlct[:-predict_next_days,:-2].min()\n",
        "        scale = max_price - min_price\n",
        "        ohlct[:-predict_next_days,:-2] = ([ohlct[:-predict_next_days,:-2] - min_price]) /scale\n",
        "\n",
        "        x.append(np.expand_dims(ohlct[:-predict_next_days,:-2], axis=-1))\n",
        "\n",
        "        # y.extend([utils.to_categorical(ohlct[-1,-1], num_classes=201)])\n",
        "        ohlct[-predict_next_days,-1] = (ohlct[-predict_next_days,-1] + 10.0) / 20.0\n",
        "        y.append(ohlct[-predict_next_days,-1])\n",
        "\n",
        "\n",
        "\n",
        "X = np.array(x)\n",
        "y = np.array(y)\n",
        "\n",
        "\n",
        "# upsample\n",
        "# dis = district\n",
        "dis_count, dis_edge = np.histogram(y, bins = 20)\n",
        "\n",
        "dis_count_max = dis_count.max() * 4\n",
        "\n",
        "dis_count = dis_count_max/dis_count\n",
        "dis_count = dis_count.astype(int)\n",
        "\n",
        "time_count = np.apply_along_axis((lambda d: dis_count[(d*100//5).astype(int)]), \\\n",
        "                                0 , y)\n",
        "\n",
        "X = np.repeat(X, time_count, axis = 0)\n",
        "y = np.repeat(y, time_count, axis = 0)\n",
        "\n",
        "length = X.shape[0]\n",
        "\n",
        "index = np.arange(length)\n",
        "np.random.shuffle(index)\n",
        "\n",
        "X = X[index]\n",
        "y = y[index]\n",
        "\n",
        "index = random.sample(range(0,length), int(length / 4))\n",
        "\n",
        "X = X[index]\n",
        "y = y[index]\n",
        "\n",
        "print(X.shape)\n",
        "print(X[1])\n",
        "print(y[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgdFoC0ZqnOx",
        "colab_type": "text"
      },
      "source": [
        "###draw data distribution 1-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMVjP76Mqonw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(y, bins = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycLBn2g9eJoz",
        "colab_type": "text"
      },
      "source": [
        "###training 1-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqCxwMbQeMqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"stock_predict_3_1-2.h5\")\n",
        "\n",
        "history = model.fit(X, y, batch_size = 1024, epochs = 16,\\\n",
        "            validation_split = 0.1, shuffle = True, \\\n",
        "            # callbacks = [tbCallBack]\\\n",
        "            )\n",
        "# plt.plot(history.history[\"acc\"])\n",
        "plt.plot(history.history[\"loss\"])\n",
        "model.save_weights(\"stock_predict_3_1-2.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMaIpUCXdKAd",
        "colab_type": "text"
      },
      "source": [
        "###drawing validation 1-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N17j1OcleJko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "stock_qty = len(ts_code)\n",
        "\n",
        "index = np.random.randint(0, stock_qty)\n",
        "\n",
        "                      \n",
        "x_plot = []\n",
        "y_plot = []\n",
        "yy_plot = []\n",
        "\n",
        "stk_data = result[result.code == ts_code.iloc[index][\"code\"]]\n",
        "length = len(stk_data)\n",
        "if ((length - days_from_ipo - predict_next_days) > window_size):\n",
        "  for l in range(days_from_ipo, length - window_size - predict_next_days):\n",
        "    ohlct = stk_data.iloc[l : l + window_size + predict_next_days] \\\n",
        "        [[\"open\", \"high\", \"low\", \"close\", \"isST\",\"pctChg\"]].values\n",
        "    if np.all(ohlct[:, -2] != 1) and \\\n",
        "       np.all(ohlct[:,-1] > -10.0) and \\\n",
        "       np.all(ohlct[:,-1] < 10.0) :\n",
        "      min_price = ohlct[:-predict_next_days,:-2].min()\n",
        "      max_price = ohlct[:-predict_next_days,:-2].max()\n",
        "      scale = (max_price - min_price)\n",
        "      ohlct[:-predict_next_days,:-2] = ([ohlct[:-predict_next_days,:-2] - min_price]) /scale\n",
        "\n",
        "      x_plot.extend([np.expand_dims(ohlct[:-predict_next_days,:-2], axis = -1)])\n",
        "\n",
        "      # ohlct[-1,-1] = (ohlct[-1,-1] + 10.0) / 20.0\n",
        "      y_plot.extend([ohlct[-predict_next_days,-1]])\n",
        "\n",
        "  X_plot = np.array(x_plot)\n",
        "  y_plot = np.array(y_plot)\n",
        "  # yy_plot = np.array(yy_plot)\n",
        "  print(ts_code.iloc[index])    \n",
        "\n",
        "else:\n",
        "  print(\"data too short, try again!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Kbry9q0dOgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"stock_predict_3_1-2.h5\")\n",
        "p = model.predict(X_plot).reshape(-1)\n",
        "\n",
        "p = p * 20.0 - 10.0\n",
        "\n",
        "plt.figure(figsize=(15,4.8))\n",
        "plt.plot(y_plot[-100:], color=\"blue\")\n",
        "plt.plot(p[-100:], color=\"red\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpCX5_PRvWDq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"stock_predict_3_1-2.h5\")\n",
        "model.evaluate(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDVfkKLHxD1a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"stock_predict_3_1-2.h5\")\n",
        "model.evaluate(X_plot, y_plot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t6hsUOdJDczM"
      },
      "source": [
        "##model 1-3: CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A5BAsBF6DczY",
        "colab": {}
      },
      "source": [
        "def make_model(summary = False):\n",
        "  K.clear_session()\n",
        "\n",
        "  input = layers.Input(shape = (window_size, factor_num - 1 ,1))\n",
        "\n",
        "\n",
        "  model_1 = layers.Conv2D(256, kernel_size =(1,4))(input)\n",
        "  model_1 = layers.Activation(\"relu\")(model_1)\n",
        "  model_1 = layers.BatchNormalization()(model_1)\n",
        "  model_1 = layers.Dropout(0.5)(model_1)\n",
        "\n",
        "  model_1 = layers.Reshape((-1, 256))(model_1)\n",
        "\n",
        "\n",
        "\n",
        "  model_5 = layers.Conv2D(256, kernel_size =(5,4))(input)\n",
        "  model_5 = layers.Activation(\"relu\")(model_5)\n",
        "  model_5 = layers.BatchNormalization()(model_5)\n",
        "  model_5 = layers.Dropout(0.5)(model_5)\n",
        "\n",
        "  model_5 = layers.Reshape((-1, 256))(model_5)\n",
        "\n",
        "\n",
        "\n",
        "  model_20 = layers.Conv2D(256, kernel_size =(20,4))(input)\n",
        "  model_20 = layers.Activation(\"relu\")(model_20)\n",
        "  model_20 = layers.BatchNormalization()(model_20)\n",
        "  model_20 = layers.Dropout(0.5)(model_20)\n",
        "\n",
        "  model_20 = layers.Reshape((-1, 256))(model_20)\n",
        "\n",
        "\n",
        "\n",
        "  model_30 = layers.Conv2D(256, kernel_size =(30,4))(input)\n",
        "  model_30 = layers.Activation(\"relu\")(model_30)\n",
        "  model_30 = layers.BatchNormalization()(model_30)\n",
        "  model_30 = layers.Dropout(0.5)(model_30)\n",
        "\n",
        "  model_30 = layers.Reshape((-1, 256))(model_30)\n",
        "\n",
        "\n",
        "  model_60 = layers.Conv2D(256, kernel_size =(60,4))(input)\n",
        "  model_60 = layers.Activation(\"relu\")(model_60)\n",
        "  model_60 = layers.BatchNormalization()(model_60)\n",
        "  model_60 = layers.Dropout(0.5)(model_60)\n",
        "\n",
        "  model_60 = layers.Reshape((-1, 256))(model_60)\n",
        "\n",
        "\n",
        "  model_90 = layers.Conv2D(256, kernel_size =(90,4))(input)\n",
        "  model_90 = layers.Activation(\"relu\")(model_90)\n",
        "  model_90 = layers.BatchNormalization()(model_90)\n",
        "  model_90 = layers.Dropout(0.5)(model_90)\n",
        "\n",
        "  model_90 = layers.Reshape((-1, 256))(model_90)\n",
        "\n",
        "\n",
        "\n",
        "  model = layers.concatenate([model_1, model_5, model_20, model_30, model_60, model_90], axis = -2)\n",
        "\n",
        "  model = layers.Flatten()(model)\n",
        "\n",
        "  # model = layers.Dense(64)(model)\n",
        "  # model = layers.Activation(\"relu\")(model)\n",
        "  # model = layers.BatchNormalization()(model)\n",
        "  # model = layers.Dropout(0.5)(model)\n",
        "\n",
        "  model = layers.Dense(32)(model)\n",
        "  model = layers.Activation(\"relu\")(model)\n",
        "  model = layers.BatchNormalization()(model)\n",
        "  model = layers.Dropout(0.5)(model)\n",
        "\n",
        "\n",
        "  model = layers.Dense(16)(model)\n",
        "  model = layers.Activation(\"relu\")(model)\n",
        "  model = layers.BatchNormalization()(model)\n",
        "  model = layers.Dropout(0.5)(model)\n",
        "\n",
        "  # model = layers.Dense(1)(model)\n",
        "\n",
        "  model = layers.Dense(4)(model)\n",
        "  model = layers.Activation(\"softmax\")(model)\n",
        "\n",
        "  model = Model(inputs = input, outputs = model)\n",
        "\n",
        "  # opt = optimizers.RMSprop(lr = 0.001, decay = 0.001)\n",
        "  opt = optimizers.Adam(lr = 0.005, decay = 0.001)\n",
        "\n",
        "  # model.compile(loss = \"mse\", optimizer = opt)\n",
        "  model.compile(loss = \"categorical_crossentropy\", optimizer = opt, metrics = [\"acc\"])\n",
        "\n",
        "  if(summary == True):\n",
        "    model.summary()\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j3AUWCwiDczo"
      },
      "source": [
        "###dataset 1-3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f0xCITARDczr",
        "colab": {}
      },
      "source": [
        "pct_of_stock  = 0.004\n",
        "stock_qty = len(ts_code)\n",
        "\n",
        "index = random.sample(range(0,stock_qty), int(stock_qty*pct_of_stock))\n",
        "\n",
        "print(np.sort(index))\n",
        "                      \n",
        "x = []\n",
        "y = []\n",
        "\n",
        "for i in index:\n",
        "  stk_data = result[result.code == ts_code.iloc[i][\"code\"]]\n",
        "  length = len(stk_data)\n",
        "  if ((length - days_from_ipo - predict_next_days) > window_size):\n",
        "    for l in range(days_from_ipo, length - window_size - predict_next_days):\n",
        "      ohlct = stk_data.iloc[l : l + window_size + predict_next_days]\\\n",
        "          [[\"open\", \"high\", \"low\", \"close\", \"isST\", \"pctChg\"]].values\n",
        "      if np.all(ohlct[:, -2] != 1) and \\\n",
        "       np.all(ohlct[:,-1] > -10.0) and \\\n",
        "       np.all(ohlct[:,-1] < 10.0) :\n",
        "        max_price = ohlct[:-predict_next_days,:-2].max()\n",
        "        min_price = ohlct[:-predict_next_days,:-2].min()\n",
        "        scale = max_price - min_price\n",
        "        ohlct[:-predict_next_days,:-2] = ([ohlct[:-predict_next_days,:-2] - min_price]) /scale\n",
        "\n",
        "        x.append(np.expand_dims(ohlct[:-predict_next_days,:-2], axis=-1))\n",
        "\n",
        "        # y.extend([utils.to_categorical(ohlct[-1,-1], num_classes=201)])\n",
        "        ohlct[-predict_next_days,-1] = (ohlct[-predict_next_days,-1] + 10.0) / 20.0\n",
        "        y.append(ohlct[-predict_next_days,-1])\n",
        "\n",
        "\n",
        "\n",
        "X = np.array(x)\n",
        "y = np.array(y)\n",
        "\n",
        "\n",
        "# upsample\n",
        "# dis = district\n",
        "dis_count, dis_edge = np.histogram(y, bins = 20)\n",
        "\n",
        "dis_count_max = dis_count.max() * 4\n",
        "\n",
        "dis_count = dis_count_max/dis_count\n",
        "dis_count = dis_count.astype(int)\n",
        "\n",
        "time_count = np.apply_along_axis((lambda d: dis_count[(d*100//5).astype(int)]), \\\n",
        "                                0 , y)\n",
        "\n",
        "X = np.repeat(X, time_count, axis = 0)\n",
        "y = np.repeat(y, time_count, axis = 0)\n",
        "\n",
        "length = X.shape[0]\n",
        "\n",
        "index = np.arange(length)\n",
        "np.random.shuffle(index)\n",
        "\n",
        "X = X[index]\n",
        "y = y[index]\n",
        "\n",
        "index = random.sample(range(0,length), int(length / 4))\n",
        "\n",
        "X = X[index]\n",
        "y = y[index]\n",
        "\n",
        "print(X.shape)\n",
        "print(X[1])\n",
        "print(y[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc1VTJ4WfPtd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#20200824\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TtE3stnXDcz1"
      },
      "source": [
        "###draw data distribution 1-3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6tq0EZ8uDcz3",
        "colab": {}
      },
      "source": [
        "plt.hist(y, bins = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lYp2sAQEDcz7"
      },
      "source": [
        "###training 1-3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zx9Ps7PODcz9",
        "colab": {}
      },
      "source": [
        "# model.load_weights(\"stock_predict_3_1-3.h5\")\n",
        "\n",
        "history = model.fit(X, y, batch_size = 256, epochs = 64,\\\n",
        "            validation_split = 0.1, shuffle = True, \\\n",
        "            # callbacks = [tbCallBack]\\\n",
        "            )\n",
        "# plt.plot(history.history[\"acc\"])\n",
        "plt.plot(history.history[\"loss\"])\n",
        "model.save_weights(\"stock_predict_3_1-3.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ga5h6zWQUi-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#reset model params file\n",
        "model = make_model()\n",
        "model.save_weights(\"stock_predict_3_1-3-set.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azBWGp6TwroY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#20200824\n",
        "\n",
        "chk_point = ModelCheckpoint(filepath='stock_predict_3_1-3-set.h5')\n",
        "# model.load_weights(\"stock_predict_3_1-3-set.h5\")\n",
        "\n",
        "\n",
        "for i in range(4):\n",
        "  print(datetime.datetime.today())\n",
        "  model = make_model()\n",
        "  model.load_weights(\"stock_predict_3_1-3-set.h5\")  \n",
        "\n",
        "  for l in range(2):\n",
        "    history = model.fit(X_t, y_t, batch_size = 1024, epochs = 10,\\\n",
        "                # validation_split = 0.1, shuffle = True, \\\n",
        "                class_weight = cls_weight,\\\n",
        "                validation_data = (X_v ,y_v),\\\n",
        "                # callbacks = [tbCallBack]\\\n",
        "                callbacks = [chk_point],\\\n",
        "                # initial_epoch = 5 \n",
        "                ) \n",
        "\n",
        "    model.save_weights(\"stock_predict_3_1-3-set.h5\")\n",
        "\n",
        "  model.save_weights(\"stock_predict_3_1-3-set_a.h5\")\n",
        "  del model\n",
        "  gc.collect()\n",
        "plt.plot(history.history[\"acc\"])\n",
        "print(datetime.datetime.today())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cH6D_yy4Dc0K"
      },
      "source": [
        "###drawing validation 1-3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XGJySR5VDc0L",
        "colab": {}
      },
      "source": [
        "\n",
        "stock_qty = len(ts_code)\n",
        "\n",
        "index = np.random.randint(0, stock_qty)\n",
        "\n",
        "                      \n",
        "x_plot = []\n",
        "y_plot = []\n",
        "yy_plot = []\n",
        "\n",
        "stk_data = result[result.code == ts_code.iloc[index][\"code\"]]\n",
        "length = len(stk_data)\n",
        "if ((length - days_from_ipo - predict_next_days) > window_size):\n",
        "  for l in range(days_from_ipo, length - window_size - predict_next_days):\n",
        "    ohlct = stk_data.iloc[l : l + window_size + predict_next_days] \\\n",
        "        [[\"open\", \"high\", \"low\", \"close\", \"isST\",\"pctChg\"]].values\n",
        "    if np.all(ohlct[:, -2] != 1) and \\\n",
        "       np.all(ohlct[:,-1] > -10.0) and \\\n",
        "       np.all(ohlct[:,-1] < 10.0) :\n",
        "      min_price = ohlct[:-predict_next_days,:-2].min()\n",
        "      max_price = ohlct[:-predict_next_days,:-2].max()\n",
        "      scale = (max_price - min_price)\n",
        "      ohlct[:-predict_next_days,:-2] = ([ohlct[:-predict_next_days,:-2] - min_price]) /scale\n",
        "\n",
        "      x_plot.extend([np.expand_dims(ohlct[:-predict_next_days,:-2], axis = -1)])\n",
        "\n",
        "      # ohlct[-1,-1] = (ohlct[-1,-1] + 10.0) / 20.0\n",
        "      y_plot.extend([ohlct[-predict_next_days,-1]])\n",
        "\n",
        "  X_plot = np.array(x_plot)\n",
        "  y_plot = np.array(y_plot)\n",
        "  # yy_plot = np.array(yy_plot)\n",
        "  print(ts_code.iloc[index])    \n",
        "\n",
        "else:\n",
        "  print(\"data too short, try again!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rjSK3PNgDc0S",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"stock_predict_3_1-3.h5\")\n",
        "p = model.predict(X_plot).reshape(-1)\n",
        "\n",
        "p = p * 20.0 - 10.0\n",
        "\n",
        "plt.figure(figsize=(15,4.8))\n",
        "plt.plot(y_plot[-100:], color=\"blue\")\n",
        "plt.plot(p[-100:], color=\"red\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fRnEIxZrDc0c",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"stock_predict_3_1-3.h5\")\n",
        "model.evaluate(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NdLHMEpQDc0g",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"stock_predict_3_1-3.h5\")\n",
        "model.evaluate(X_plot, y_plot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Jz7H77AjNK9p"
      },
      "source": [
        "##model 1-4: CNN + LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z0zrUfHFNK9t",
        "colab": {}
      },
      "source": [
        "K.clear_session()\n",
        "\n",
        "input = layers.Input(shape = (window_size, factor_num - 1 ,1))\n",
        "\n",
        "\n",
        "model_1 = layers.Conv2D(256, kernel_size =(1,4))(input)\n",
        "model_1 = layers.Activation(\"relu\")(model_1)\n",
        "model_1 = layers.BatchNormalization()(model_1)\n",
        "model_1 = layers.Dropout(0.5)(model_1)\n",
        "\n",
        "model_1 = layers.Reshape((-1,256))(model_1)\n",
        "\n",
        "model_1 = layers.LSTM(256)(model_1)\n",
        "\n",
        "\n",
        "\n",
        "model_5 = layers.Conv2D(256, kernel_size =(5,4))(input)\n",
        "model_5 = layers.Activation(\"relu\")(model_5)\n",
        "model_5 = layers.BatchNormalization()(model_5)\n",
        "model_5 = layers.Dropout(0.5)(model_5)\n",
        "\n",
        "model_5 = layers.Reshape((-1,256))(model_5)\n",
        "\n",
        "model_5 = layers.LSTM(256)(model_5)\n",
        "\n",
        "model_10 = layers.Conv2D(256, kernel_size =(5,4))(input)\n",
        "model_10 = layers.Activation(\"relu\")(model_10)\n",
        "model_10 = layers.BatchNormalization()(model_10)\n",
        "model_10 = layers.Dropout(0.5)(model_10)\n",
        "\n",
        "model_10 = layers.Reshape((-1,256))(model_10)\n",
        "\n",
        "model_10 = layers.LSTM(256)(model_10)\n",
        "\n",
        "model_20 = layers.Conv2D(256, kernel_size =(20,4))(input)\n",
        "model_20 = layers.Activation(\"relu\")(model_20)\n",
        "model_20 = layers.BatchNormalization()(model_20)\n",
        "model_20 = layers.Dropout(0.5)(model_20)\n",
        "\n",
        "model_20 = layers.Reshape((-1,256))(model_20)\n",
        "\n",
        "model_20 = layers.LSTM(256)(model_20)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model_30 = layers.Conv2D(256, kernel_size =(30,4))(input)\n",
        "model_30 = layers.Activation(\"relu\")(model_30)\n",
        "model_30 = layers.BatchNormalization()(model_30)\n",
        "model_30 = layers.Dropout(0.5)(model_30)\n",
        "\n",
        "model_30 = layers.Reshape((-1,256))(model_30)\n",
        "\n",
        "model_30 = layers.LSTM(256)(model_30)\n",
        "\n",
        "\n",
        "\n",
        "model = layers.concatenate([model_1, model_5, model_10, model_20, model_30], axis = -1)\n",
        "\n",
        "model = layers.Dense(256)(model)\n",
        "model = layers.Activation(\"relu\")(model)\n",
        "model = layers.BatchNormalization()(model)\n",
        "model = layers.Dropout(0.5)(model)\n",
        "\n",
        "model = layers.Dense(128)(model)\n",
        "model = layers.Activation(\"relu\")(model)\n",
        "model = layers.BatchNormalization()(model)\n",
        "model = layers.Dropout(0.5)(model)\n",
        "\n",
        "model = layers.Dense(64)(model)\n",
        "model = layers.Activation(\"relu\")(model)\n",
        "model = layers.BatchNormalization()(model)\n",
        "model = layers.Dropout(0.5)(model)\n",
        "\n",
        "model = layers.Dense(32)(model)\n",
        "model = layers.Activation(\"relu\")(model)\n",
        "model = layers.BatchNormalization()(model)\n",
        "model = layers.Dropout(0.5)(model)\n",
        "\n",
        "model = layers.Dense(1)(model)\n",
        "\n",
        "model = Model(inputs = input, outputs = model)\n",
        "\n",
        "opt = optimizers.RMSprop(lr = 0.001, decay = 0.001)\n",
        "\n",
        "model.compile(loss = \"mse\", optimizer = opt)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4ji2nW0xNK9-"
      },
      "source": [
        "###dataset 1-4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V8tzPppANK-B",
        "colab": {}
      },
      "source": [
        "pct_of_stock  = 0.01\n",
        "stock_qty = len(ts_code)\n",
        "\n",
        "index = random.sample(range(0,stock_qty), int(stock_qty*pct_of_stock))\n",
        "\n",
        "print(np.sort(index))\n",
        "                      \n",
        "x = []\n",
        "y = []\n",
        "\n",
        "for i in index:\n",
        "  stk_data = result[result.code == ts_code.iloc[i][\"code\"]]\n",
        "  length = len(stk_data)\n",
        "  if ((length - days_from_ipo - predict_next_days) > window_size):\n",
        "    for l in range(days_from_ipo, length - window_size - predict_next_days):\n",
        "      ohlct = stk_data.iloc[l : l + window_size + predict_next_days]\\\n",
        "          [[\"open\", \"high\", \"low\", \"close\", \"isST\", \"pctChg\"]].values\n",
        "      if np.all(ohlct[:, -2] != 1) and \\\n",
        "       np.all(ohlct[:,-1] > -10.0) and \\\n",
        "       np.all(ohlct[:,-1] < 10.0) :\n",
        "        max_price = ohlct[:-predict_next_days,:-2].max()\n",
        "        min_price = ohlct[:-predict_next_days,:-2].min()\n",
        "        scale = max_price - min_price\n",
        "        ohlct[:-predict_next_days,:-2] = ([ohlct[:-predict_next_days,:-2] - min_price]) /scale\n",
        "\n",
        "        x.append(np.expand_dims(ohlct[:-predict_next_days,:-2], axis=-1))\n",
        "\n",
        "        # y.extend([utils.to_categorical(ohlct[-1,-1], num_classes=201)])\n",
        "        ohlct[-predict_next_days,-1] = (ohlct[-predict_next_days,-1] + 10.0) / 20.0\n",
        "        y.append(ohlct[-predict_next_days,-1])\n",
        "\n",
        "\n",
        "\n",
        "X = np.array(x)\n",
        "y = np.array(y)\n",
        "\n",
        "\n",
        "# upsample\n",
        "# dis = district\n",
        "dis_count, dis_edge = np.histogram(y, bins = 20)\n",
        "\n",
        "dis_count_max = dis_count.max() * 4\n",
        "\n",
        "dis_count = dis_count_max/dis_count\n",
        "dis_count = dis_count.astype(int)\n",
        "\n",
        "time_count = np.apply_along_axis((lambda d: dis_count[(d*100//5).astype(int)]), \\\n",
        "                                0 , y)\n",
        "\n",
        "X = np.repeat(X, time_count, axis = 0)\n",
        "y = np.repeat(y, time_count, axis = 0)\n",
        "\n",
        "length = X.shape[0]\n",
        "\n",
        "index = np.arange(length)\n",
        "np.random.shuffle(index)\n",
        "\n",
        "X = X[index]\n",
        "y = y[index]\n",
        "\n",
        "index = random.sample(range(0,length), int(length / 4))\n",
        "\n",
        "X = X[index]\n",
        "y = y[index]\n",
        "\n",
        "print(X.shape)\n",
        "print(X[1])\n",
        "print(y[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0n5kGdKdNK-L"
      },
      "source": [
        "###draw data distribution 1-4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_jkxO4iBNK-O",
        "colab": {}
      },
      "source": [
        "plt.hist(y, bins = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Nh9nRcdaNK-U"
      },
      "source": [
        "###training 1-4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s6DkXeRWNK-V",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"stock_predict_3_1-4.h5\")\n",
        "\n",
        "history = model.fit(X, y, batch_size = 1024, epochs = 24,\\\n",
        "            validation_split = 0.1, shuffle = True, \\\n",
        "            # callbacks = [tbCallBack]\\\n",
        "            )\n",
        "# plt.plot(history.history[\"acc\"])\n",
        "plt.plot(history.history[\"loss\"])\n",
        "model.save_weights(\"stock_predict_3_1-4.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XitBIfkFNK-d"
      },
      "source": [
        "###drawing validation 1-4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pMF-aFYHNK-g",
        "colab": {}
      },
      "source": [
        "\n",
        "stock_qty = len(ts_code)\n",
        "\n",
        "index = np.random.randint(0, stock_qty)\n",
        "\n",
        "                      \n",
        "x_plot = []\n",
        "y_plot = []\n",
        "yy_plot = []\n",
        "\n",
        "stk_data = result[result.code == ts_code.iloc[index][\"code\"]]\n",
        "length = len(stk_data)\n",
        "if ((length - days_from_ipo - predict_next_days) > window_size):\n",
        "  for l in range(days_from_ipo, length - window_size - predict_next_days):\n",
        "    ohlct = stk_data.iloc[l : l + window_size + predict_next_days] \\\n",
        "        [[\"open\", \"high\", \"low\", \"close\", \"isST\",\"pctChg\"]].values\n",
        "    if np.all(ohlct[:, -2] != 1) and \\\n",
        "       np.all(ohlct[:,-1] > -10.0) and \\\n",
        "       np.all(ohlct[:,-1] < 10.0) :\n",
        "      min_price = ohlct[:-predict_next_days,:-2].min()\n",
        "      max_price = ohlct[:-predict_next_days,:-2].max()\n",
        "      scale = (max_price - min_price)\n",
        "      ohlct[:-predict_next_days,:-2] = ([ohlct[:-predict_next_days,:-2] - min_price]) /scale\n",
        "\n",
        "      x_plot.extend([np.expand_dims(ohlct[:-predict_next_days,:-2], axis = -1)])\n",
        "\n",
        "      # ohlct[-1,-1] = (ohlct[-1,-1] + 10.0) / 20.0\n",
        "      y_plot.extend([ohlct[-predict_next_days,-1]])\n",
        "\n",
        "  X_plot = np.array(x_plot)\n",
        "  y_plot = np.array(y_plot)\n",
        "  # yy_plot = np.array(yy_plot)\n",
        "  print(ts_code.iloc[index])    \n",
        "\n",
        "else:\n",
        "  print(\"data too short, try again!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MMwImG5KNK-m",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"stock_predict_3_1-4.h5\")\n",
        "p = model.predict(X_plot).reshape(-1)\n",
        "\n",
        "p = p * 20.0 - 10.0\n",
        "\n",
        "plt.figure(figsize=(15,4.8))\n",
        "plt.plot(y_plot[-100:], color=\"blue\")\n",
        "plt.plot(p[-100:], color=\"red\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IG3zMp0SNK-r",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"stock_predict_3_1-4.h5\")\n",
        "model.evaluate(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cJUgwzrjNK_J",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"stock_predict_3_1-4.h5\")\n",
        "model.evaluate(X_plot, y_plot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NeK-E3zCsBub"
      },
      "source": [
        "##model 1-5: CNN + LSTM with dif params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hDadEhEQsBun",
        "colab": {}
      },
      "source": [
        "K.clear_session()\n",
        "\n",
        "input = layers.Input(shape = (window_size, factor_num - 1 ,1))\n",
        "\n",
        "\n",
        "model_1 = layers.Conv2D(64, kernel_size =(1,4))(input)\n",
        "model_1 = layers.Activation(\"relu\")(model_1)\n",
        "model_1 = layers.BatchNormalization()(model_1)\n",
        "model_1 = layers.Dropout(0.5)(model_1)\n",
        "\n",
        "model_1 = layers.Reshape((-1,64))(model_1)\n",
        "\n",
        "model_1 = layers.LSTM(256)(model_1)\n",
        "\n",
        "\n",
        "\n",
        "model_5 = layers.Conv2D(128, kernel_size =(5,4))(input)\n",
        "model_5 = layers.Activation(\"relu\")(model_5)\n",
        "model_5 = layers.BatchNormalization()(model_5)\n",
        "model_5 = layers.Dropout(0.5)(model_5)\n",
        "\n",
        "model_5 = layers.Reshape((-1,128))(model_5)\n",
        "\n",
        "model_5 = layers.LSTM(256)(model_5)\n",
        "\n",
        "model_10 = layers.Conv2D(256, kernel_size =(5,4))(input)\n",
        "model_10 = layers.Activation(\"relu\")(model_10)\n",
        "model_10 = layers.BatchNormalization()(model_10)\n",
        "model_10 = layers.Dropout(0.5)(model_10)\n",
        "\n",
        "model_10 = layers.Reshape((-1,256))(model_10)\n",
        "\n",
        "model_10 = layers.LSTM(256)(model_10)\n",
        "\n",
        "model_20 = layers.Conv2D(512, kernel_size =(20,4))(input)\n",
        "model_20 = layers.Activation(\"relu\")(model_20)\n",
        "model_20 = layers.BatchNormalization()(model_20)\n",
        "model_20 = layers.Dropout(0.5)(model_20)\n",
        "\n",
        "model_20 = layers.Reshape((-1,512))(model_20)\n",
        "\n",
        "model_20 = layers.LSTM(256)(model_20)\n",
        "\n",
        "\n",
        "\n",
        "model_30 = layers.Conv2D(1024, kernel_size =(30,4))(input)\n",
        "model_30 = layers.Activation(\"relu\")(model_30)\n",
        "model_30 = layers.BatchNormalization()(model_30)\n",
        "model_30 = layers.Dropout(0.5)(model_30)\n",
        "\n",
        "model_30 = layers.Reshape((-1,1024))(model_30)\n",
        "\n",
        "model_30 = layers.LSTM(256)(model_30)\n",
        "\n",
        "\n",
        "\n",
        "model = layers.concatenate([model_1, model_5, model_10, model_20, model_30], axis = -1)\n",
        "\n",
        "model = layers.Dense(256)(model)\n",
        "model = layers.Activation(\"relu\")(model)\n",
        "model = layers.BatchNormalization()(model)\n",
        "model = layers.Dropout(0.5)(model)\n",
        "\n",
        "model = layers.Dense(128)(model)\n",
        "model = layers.Activation(\"relu\")(model)\n",
        "model = layers.BatchNormalization()(model)\n",
        "model = layers.Dropout(0.5)(model)\n",
        "\n",
        "model = layers.Dense(64)(model)\n",
        "model = layers.Activation(\"relu\")(model)\n",
        "model = layers.BatchNormalization()(model)\n",
        "model = layers.Dropout(0.5)(model)\n",
        "\n",
        "model = layers.Dense(32)(model)\n",
        "model = layers.Activation(\"relu\")(model)\n",
        "model = layers.BatchNormalization()(model)\n",
        "model = layers.Dropout(0.5)(model)\n",
        "\n",
        "model = layers.Dense(1)(model)\n",
        "\n",
        "model = Model(inputs = input, outputs = model)\n",
        "\n",
        "opt = optimizers.RMSprop(lr = 0.001, decay = 0.001)\n",
        "\n",
        "model.compile(loss = \"mse\", optimizer = opt)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QCpq_WYJsBux"
      },
      "source": [
        "###dataset 1-5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0vhbfyRhsBu0",
        "colab": {}
      },
      "source": [
        "pct_of_stock  = 0.01\n",
        "stock_qty = len(ts_code)\n",
        "\n",
        "index = random.sample(range(0,stock_qty), int(stock_qty*pct_of_stock))\n",
        "\n",
        "print(np.sort(index))\n",
        "                      \n",
        "x = []\n",
        "y = []\n",
        "\n",
        "for i in index:\n",
        "  stk_data = result[result.code == ts_code.iloc[i][\"code\"]]\n",
        "  length = len(stk_data)\n",
        "  if ((length - days_from_ipo - predict_next_days) > window_size):\n",
        "    for l in range(days_from_ipo, length - window_size - predict_next_days):\n",
        "      ohlct = stk_data.iloc[l : l + window_size + predict_next_days]\\\n",
        "          [[\"open\", \"high\", \"low\", \"close\", \"isST\", \"pctChg\"]].values\n",
        "      if np.all(ohlct[:, -2] != 1) and \\\n",
        "       np.all(ohlct[:,-1] > -10.0) and \\\n",
        "       np.all(ohlct[:,-1] < 10.0) :\n",
        "        max_price = ohlct[:-predict_next_days,:-2].max()\n",
        "        min_price = ohlct[:-predict_next_days,:-2].min()\n",
        "        scale = max_price - min_price\n",
        "        ohlct[:-predict_next_days,:-2] = ([ohlct[:-predict_next_days,:-2] - min_price]) /scale\n",
        "\n",
        "        x.append(np.expand_dims(ohlct[:-predict_next_days,:-2], axis=-1))\n",
        "\n",
        "        # y.extend([utils.to_categorical(ohlct[-1,-1], num_classes=201)])\n",
        "        ohlct[-predict_next_days,-1] = (ohlct[-predict_next_days,-1] + 10.0) / 20.0\n",
        "        y.append(ohlct[-predict_next_days,-1])\n",
        "\n",
        "\n",
        "\n",
        "X = np.array(x)\n",
        "y = np.array(y)\n",
        "\n",
        "\n",
        "# upsample\n",
        "# dis = district\n",
        "dis_count, dis_edge = np.histogram(y, bins = 20)\n",
        "\n",
        "dis_count_max = dis_count.max() * 4\n",
        "\n",
        "dis_count = dis_count_max/dis_count\n",
        "dis_count = dis_count.astype(int)\n",
        "\n",
        "time_count = np.apply_along_axis((lambda d: dis_count[(d*100//5).astype(int)]), \\\n",
        "                                0 , y)\n",
        "\n",
        "X = np.repeat(X, time_count, axis = 0)\n",
        "y = np.repeat(y, time_count, axis = 0)\n",
        "\n",
        "length = X.shape[0]\n",
        "\n",
        "index = np.arange(length)\n",
        "np.random.shuffle(index)\n",
        "\n",
        "X = X[index]\n",
        "y = y[index]\n",
        "\n",
        "index = random.sample(range(0,length), int(length / 4))\n",
        "\n",
        "X = X[index]\n",
        "y = y[index]\n",
        "\n",
        "print(X.shape)\n",
        "print(X[1])\n",
        "print(y[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IOpu9aoFsBu-"
      },
      "source": [
        "###draw data distribution 1-5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G94R0K9vsBvB",
        "colab": {}
      },
      "source": [
        "plt.hist(y, bins = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mFHZhz3NsBvU"
      },
      "source": [
        "###training 1-5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ktctvB8lsBvY",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"stock_predict_3_1-5.h5\")\n",
        "\n",
        "history = model.fit(X, y, batch_size = 1024, epochs = 24,\\\n",
        "            validation_split = 0.1, shuffle = True, \\\n",
        "            # callbacks = [tbCallBack]\\\n",
        "            )\n",
        "# plt.plot(history.history[\"acc\"])\n",
        "plt.plot(history.history[\"loss\"])\n",
        "model.save_weights(\"stock_predict_3_1-5.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FOqy4bPDjgz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"stock_predict_3_1-5.h5\")\n",
        "\n",
        "history = model.fit(X, y, batch_size = 1024, epochs = 64,\\\n",
        "            validation_split = 0.1, shuffle = True, \\\n",
        "            # callbacks = [tbCallBack]\\\n",
        "            )\n",
        "# plt.plot(history.history[\"acc\"])\n",
        "plt.plot(history.history[\"loss\"])\n",
        "model.save_weights(\"stock_predict_3_1-5.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8WUuXH9nsBvj"
      },
      "source": [
        "###drawing validation 1-5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "82V0HmWFsBvl",
        "colab": {}
      },
      "source": [
        "\n",
        "stock_qty = len(ts_code)\n",
        "\n",
        "index = np.random.randint(0, stock_qty)\n",
        "\n",
        "                      \n",
        "x_plot = []\n",
        "y_plot = []\n",
        "yy_plot = []\n",
        "\n",
        "stk_data = result[result.code == ts_code.iloc[index][\"code\"]]\n",
        "length = len(stk_data)\n",
        "if ((length - days_from_ipo - predict_next_days) > window_size):\n",
        "  for l in range(days_from_ipo, length - window_size - predict_next_days):\n",
        "    ohlct = stk_data.iloc[l : l + window_size + predict_next_days] \\\n",
        "        [[\"open\", \"high\", \"low\", \"close\", \"isST\",\"pctChg\"]].values\n",
        "    if np.all(ohlct[:, -2] != 1) and \\\n",
        "       np.all(ohlct[:,-1] > -10.0) and \\\n",
        "       np.all(ohlct[:,-1] < 10.0) :\n",
        "      min_price = ohlct[:-predict_next_days,:-2].min()\n",
        "      max_price = ohlct[:-predict_next_days,:-2].max()\n",
        "      scale = (max_price - min_price)\n",
        "      ohlct[:-predict_next_days,:-2] = ([ohlct[:-predict_next_days,:-2] - min_price]) /scale\n",
        "\n",
        "      x_plot.extend([np.expand_dims(ohlct[:-predict_next_days,:-2], axis = -1)])\n",
        "\n",
        "      # ohlct[-1,-1] = (ohlct[-1,-1] + 10.0) / 20.0\n",
        "      y_plot.extend([ohlct[-predict_next_days,-1]])\n",
        "\n",
        "  X_plot = np.array(x_plot)\n",
        "  y_plot = np.array(y_plot)\n",
        "  # yy_plot = np.array(yy_plot)\n",
        "  print(ts_code.iloc[index])    \n",
        "\n",
        "else:\n",
        "  print(\"data too short, try again!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2U-DxIc_sBvt",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"stock_predict_3_1-5.h5\")\n",
        "p = model.predict(X_plot).reshape(-1)\n",
        "\n",
        "p = p * 20.0 - 10.0\n",
        "\n",
        "plt.figure(figsize=(15,4.8))\n",
        "plt.plot(y_plot[-100:], color=\"blue\")\n",
        "plt.plot(p[-100:], color=\"red\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iHAjTtQVsBvx",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"stock_predict_3_1-5.h5\")\n",
        "model.evaluate(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZghInDdrsBv0",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"stock_predict_3_1-5.h5\")\n",
        "model.evaluate(X_plot, y_plot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1_k6_jXNQx6",
        "colab_type": "text"
      },
      "source": [
        "###get data of specific code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3t3nvTRA5asI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s_code = \"sh.000016\"\n",
        "\n",
        "s_data_file = s_code + \".csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q9aqqD2EfEm0",
        "colab": {}
      },
      "source": [
        "\n",
        "s_code = \"sh.000016\"\n",
        "\n",
        "s_data_file = s_code + \".csv\"\n",
        "\n",
        "bs.login()\n",
        "\n",
        "rs = bs.query_history_k_data_plus(s_code, \",\".join(data_fields),\\\n",
        "                          start_date = start_date, end_date = end_date,\\\n",
        "                            frequency = \"d\", adjustflag = adjustflag)\n",
        "\n",
        "data_list = []\n",
        "while (rs.error_code == \"0\") and rs.next():\n",
        "    row_data = rs.get_row_data()\n",
        "    if(row_data[6] == \"1\"):         \n",
        "        data_list.append(row_data)\n",
        "s_result = pd.DataFrame(data_list, columns = rs.fields)\n",
        "s_result.to_csv(s_data_file)\n",
        "print(s_result.head())\n",
        "\n",
        "bs.logout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qYIH7kzfsNh",
        "colab_type": "text"
      },
      "source": [
        "###dataset of specific code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Xh0IgWV-fHcE",
        "colab": {}
      },
      "source": [
        "x = []\n",
        "y = []\n",
        "\n",
        "stk_data = pd.read_csv(s_data_file)\n",
        "length = len(stk_data)\n",
        "if ((length - days_from_ipo - predict_next_days) > window_size):\n",
        " for l in range(days_from_ipo, length - window_size - predict_next_days):\n",
        "  ohlct = stk_data.iloc[l : l + window_size + predict_next_days]\\\n",
        "          [[\"open\", \"high\", \"low\", \"close\", \"isST\", \"pctChg\"]].values\n",
        "  if np.all(ohlct[:, -2] != 1) and \\\n",
        "     np.all(ohlct[:,-1] > -10.0) and \\\n",
        "      np.all(ohlct[:,-1] < 10.0) :\n",
        "        max_price = ohlct[:-predict_next_days,:-2].max()\n",
        "  min_price = ohlct[:-predict_next_days,:-2].min()\n",
        "  scale = max_price - min_price\n",
        "  ohlct[:-predict_next_days,:-2] = ([ohlct[:-predict_next_days,:-2] - min_price]) /scale\n",
        "\n",
        "  x.append(np.expand_dims(ohlct[:-predict_next_days,:-2], axis=-1))\n",
        "\n",
        "  # y.extend([utils.to_categorical(ohlct[-1,-1], num_classes=201)])\n",
        "  ohlct[-predict_next_days,-1] = (ohlct[-predict_next_days,-1] + 10.0) / 20.0\n",
        "  y.append(ohlct[-predict_next_days,-1])\n",
        "\n",
        "\n",
        "s_X = np.array(x)\n",
        "s_y = np.array(y)\n",
        "\n",
        "\n",
        "# upsample\n",
        "# dis = district\n",
        "dis_count, dis_edge = np.histogram(s_y, bins = 20)\n",
        "\n",
        "dis_count_max = dis_count.max() * 4\n",
        "\n",
        "dis_count = dis_count_max/dis_count\n",
        "dis_count = dis_count.astype(int)\n",
        "\n",
        "time_count = np.apply_along_axis((lambda d: dis_count[(d*100//5).astype(int)]), \\\n",
        "                                0 , s_y)\n",
        "\n",
        "s_X = np.repeat(s_X, time_count, axis = 0)\n",
        "s_y = np.repeat(s_y, time_count, axis = 0)\n",
        "\n",
        "length = s_X.shape[0]\n",
        "\n",
        "index = np.arange(length)\n",
        "np.random.shuffle(index)\n",
        "\n",
        "s_X = s_X[index]\n",
        "s_y = s_y[index]\n",
        "\n",
        "index = random.sample(range(0,length), int(length / 4))\n",
        "\n",
        "s_X = s_X[index]\n",
        "s_y = s_y[index]\n",
        "\n",
        "print(s_X.shape)\n",
        "print(s_X[1])\n",
        "print(s_y[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vj_SJEQ_f2-h",
        "colab_type": "text"
      },
      "source": [
        "###training basing on model1-5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3fEb2kdf-Hc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.load_weights(\"stock_predict_3_1-5.h5\")\n",
        "model.load_weights(s_data_file + \".h5\")\n",
        "\n",
        "history = model.fit(s_X, s_y, batch_size = 128, epochs = 24,\\\n",
        "            validation_split = 0.1, shuffle = True, \\\n",
        "            # callbacks = [tbCallBack]\\\n",
        "            )\n",
        "# plt.plot(history.history[\"acc\"])\n",
        "plt.plot(history.history[\"loss\"])\n",
        "model.save_weights(s_data_file + \".h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyRaLilwhXDe",
        "colab_type": "text"
      },
      "source": [
        "###get more data for specific code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brNM09tUhc3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bs.login()\n",
        "\n",
        "s_date = \"2018-06-01\"\n",
        "e_date = \"2019-09-30\"\n",
        "\n",
        "rs = bs.query_history_k_data_plus(s_code, \",\".join(data_fields),\\\n",
        "                          start_date = s_date, end_date = e_date,\\\n",
        "                            frequency = \"d\", adjustflag = adjustflag)\n",
        "\n",
        "data_list = []\n",
        "while (rs.error_code == \"0\") and rs.next():\n",
        "    row_data = rs.get_row_data()\n",
        "    if(row_data[6] == \"1\"):         \n",
        "        data_list.append(row_data)\n",
        "p_result = pd.DataFrame(data_list, columns = rs.fields)\n",
        "\n",
        "print(p_result.head())\n",
        "\n",
        "bs.logout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unLFYTKkDXEo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(p_result.loc[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bs-RKeyFgyRP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(p_result.count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51tkVCF26Agg",
        "colab_type": "text"
      },
      "source": [
        "###predict for specific code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q90PLdFU6eYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "                      \n",
        "x_plot = []\n",
        "y_plot = []\n",
        "\n",
        "stk_data = p_result\n",
        "length = len(stk_data)\n",
        "if ((length - predict_next_days) > window_size):\n",
        "  for l in range(length - window_size - predict_next_days):\n",
        "    ohlct = stk_data.iloc[l : l + window_size + predict_next_days] \\\n",
        "        [[\"open\", \"high\", \"low\", \"close\", \"isST\",\"pctChg\"]].values\n",
        "    ohlct = ohlct.astype(\"float\")\n",
        "    if np.all(ohlct[:, -2] != 1) and \\\n",
        "       np.all(ohlct[:,-1] > -10.0) and \\\n",
        "       np.all(ohlct[:,-1] < 10.0) :\n",
        "      min_price = ohlct[:-predict_next_days,:-2].min()\n",
        "      max_price = ohlct[:-predict_next_days,:-2].max()\n",
        "      scale = (max_price - min_price)\n",
        "      ohlct[:-predict_next_days,:-2] = ([ohlct[:-predict_next_days,:-2] - min_price]) /scale\n",
        "\n",
        "      x_plot.extend([np.expand_dims(ohlct[:-predict_next_days,:-2], axis = -1)])\n",
        "\n",
        "      # ohlct[-predict_next_days,-1] = (ohlct[-predict_next_days,-1] + 10.0) / 20.0\n",
        "      y_plot.extend([ohlct[-predict_next_days,-1]])\n",
        "\n",
        "  X_plot = np.array(x_plot)\n",
        "  y_plot = np.array(y_plot)\n",
        "  # yy_plot = np.array(yy_plot)  \n",
        "\n",
        "else:\n",
        "  print(\"data too short, try again!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc8MyjZu6Lgo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"sh.000016.csv.h5\")\n",
        "# model.load_weights(\"stock_predict_3_1-5.h5\")\n",
        "\n",
        "p = model.predict(X_plot).reshape(-1)\n",
        "\n",
        "p = p * 20.0 - 10.0\n",
        "\n",
        "plt.figure(figsize=(15,4.8))\n",
        "plt.plot(y_plot, color=\"blue\")\n",
        "plt.plot(p, color=\"red\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LBQKvnNyvv76"
      },
      "source": [
        "##model 1-6: CNN + LSTM with dif params by crossentrpy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lzcJ4msjvv79",
        "colab": {}
      },
      "source": [
        "K.clear_session()\n",
        "\n",
        "input = layers.Input(shape = (window_size, factor_num - 1 ,1))\n",
        "\n",
        "\n",
        "model_1 = layers.Conv2D(64, kernel_size =(1,4))(input)\n",
        "model_1 = layers.Activation(\"relu\")(model_1)\n",
        "model_1 = layers.BatchNormalization()(model_1)\n",
        "model_1 = layers.Dropout(0.5)(model_1)\n",
        "\n",
        "model_1 = layers.Reshape((-1,64))(model_1)\n",
        "\n",
        "model_1 = layers.LSTM(256)(model_1)\n",
        "\n",
        "\n",
        "\n",
        "model_5 = layers.Conv2D(128, kernel_size =(5,4))(input)\n",
        "model_5 = layers.Activation(\"relu\")(model_5)\n",
        "model_5 = layers.BatchNormalization()(model_5)\n",
        "model_5 = layers.Dropout(0.5)(model_5)\n",
        "\n",
        "model_5 = layers.Reshape((-1,128))(model_5)\n",
        "\n",
        "model_5 = layers.LSTM(256)(model_5)\n",
        "\n",
        "model_10 = layers.Conv2D(256, kernel_size =(5,4))(input)\n",
        "model_10 = layers.Activation(\"relu\")(model_10)\n",
        "model_10 = layers.BatchNormalization()(model_10)\n",
        "model_10 = layers.Dropout(0.5)(model_10)\n",
        "\n",
        "model_10 = layers.Reshape((-1,256))(model_10)\n",
        "\n",
        "model_10 = layers.LSTM(256)(model_10)\n",
        "\n",
        "model_20 = layers.Conv2D(512, kernel_size =(20,4))(input)\n",
        "model_20 = layers.Activation(\"relu\")(model_20)\n",
        "model_20 = layers.BatchNormalization()(model_20)\n",
        "model_20 = layers.Dropout(0.5)(model_20)\n",
        "\n",
        "model_20 = layers.Reshape((-1,512))(model_20)\n",
        "\n",
        "model_20 = layers.LSTM(256)(model_20)\n",
        "\n",
        "\n",
        "\n",
        "model_30 = layers.Conv2D(1024, kernel_size =(30,4))(input)\n",
        "model_30 = layers.Activation(\"relu\")(model_30)\n",
        "model_30 = layers.BatchNormalization()(model_30)\n",
        "model_30 = layers.Dropout(0.5)(model_30)\n",
        "\n",
        "model_30 = layers.Reshape((-1,1024))(model_30)\n",
        "\n",
        "model_30 = layers.LSTM(256)(model_30)\n",
        "\n",
        "\n",
        "\n",
        "model = layers.concatenate([model_1, model_5, model_10, model_20, model_30], axis = -1)\n",
        "\n",
        "model = layers.Dense(256)(model)\n",
        "model = layers.Activation(\"relu\")(model)\n",
        "model = layers.BatchNormalization()(model)\n",
        "model = layers.Dropout(0.5)(model)\n",
        "\n",
        "model = layers.Dense(128)(model)\n",
        "model = layers.Activation(\"relu\")(model)\n",
        "model = layers.BatchNormalization()(model)\n",
        "model = layers.Dropout(0.5)(model)\n",
        "\n",
        "model = layers.Dense(64)(model)\n",
        "model = layers.Activation(\"relu\")(model)\n",
        "model = layers.BatchNormalization()(model)\n",
        "model = layers.Dropout(0.5)(model)\n",
        "\n",
        "model = layers.Dense(32)(model)\n",
        "model = layers.Activation(\"relu\")(model)\n",
        "model = layers.BatchNormalization()(model)\n",
        "model = layers.Dropout(0.5)(model)\n",
        "\n",
        "model = layers.Dense(4)(model)\n",
        "model = layers.Activation(\"softmax\")(model)\n",
        "\n",
        "model = Model(inputs = input, outputs = model)\n",
        "\n",
        "opt = optimizers.RMSprop(lr = 0.001, decay = 0.001)\n",
        "\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer = opt, metrics = [\"acc\"])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "L7ibvQRGvv8G"
      },
      "source": [
        "###dataset 1-6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cHX8zzMZvv8H",
        "colab": {}
      },
      "source": [
        "pct_of_stock  = 0.04\n",
        "stock_qty = len(ts_code)\n",
        "edge = 3.0\n",
        "\n",
        "index = random.sample(range(0,stock_qty), int(stock_qty*pct_of_stock))\n",
        "\n",
        "print(np.sort(index))\n",
        "                      \n",
        "x = []\n",
        "y = []\n",
        "\n",
        "for i in index:\n",
        "  stk_data = result[result.code == ts_code.iloc[i][\"code\"]]\n",
        "  length = len(stk_data)\n",
        "  if ((length - days_from_ipo - predict_next_days) > window_size):\n",
        "    for l in range(days_from_ipo, length - window_size - predict_next_days):\n",
        "      ohlct = stk_data.iloc[l : l + window_size + predict_next_days]\\\n",
        "          [[\"open\", \"high\", \"low\", \"close\", \"isST\", \"pctChg\"]].values\n",
        "      if np.all(ohlct[:, -2] != 1) and \\\n",
        "       np.all(ohlct[:,-1] > -10.0) and \\\n",
        "       np.all(ohlct[:,-1] < 10.0) :\n",
        "        max_price = ohlct[:-predict_next_days,:-2].max()\n",
        "        min_price = ohlct[:-predict_next_days,:-2].min()\n",
        "        scale = max_price - min_price\n",
        "        ohlct[:-predict_next_days,:-2] = ([ohlct[:-predict_next_days,:-2] - min_price]) /scale\n",
        "\n",
        "        x.append(np.expand_dims(ohlct[:-predict_next_days,:-2], axis=-1))\n",
        "\n",
        "        # y.extend([utils.to_categorical(ohlct[-1,-1], num_classes=201)])\n",
        "        if ohlct[-predict_next_days,-1] <= -edge:\n",
        "          y.append(0)\n",
        "        elif ohlct[-predict_next_days,-1] > -edge and \\\n",
        "          ohlct[-predict_next_days,-1] <= 0:\n",
        "          y.append(1)\n",
        "        elif ohlct[-predict_next_days,-1] > 0 and \\\n",
        "          ohlct[-predict_next_days,-1] <= edge:\n",
        "          y.append(2)\n",
        "        else:\n",
        "          y.append(3)\n",
        "\n",
        "\n",
        "X = np.array(x)\n",
        "y = np.array(y)\n",
        "\n",
        "\n",
        "# upsample\n",
        "# dis = district\n",
        "\n",
        "dis_count, dis_edge = np.histogram(y, bins = 4)\n",
        "\n",
        "dis_count_max = dis_count.max()\n",
        "\n",
        "dis_count = dis_count_max/dis_count\n",
        "dis_count = dis_count.astype(int)\n",
        "\n",
        "time_count = np.apply_along_axis((lambda d: dis_count[d.astype(int)]), \\\n",
        "                                0 , y)\n",
        "\n",
        "X = np.repeat(X, time_count, axis = 0)\n",
        "y = np.repeat(y, time_count, axis = 0)\n",
        "\n",
        "# shuffle dataset\n",
        "\n",
        "length = X.shape[0]\n",
        "\n",
        "index = np.arange(length)\n",
        "np.random.shuffle(index)\n",
        "\n",
        "X = X[index]\n",
        "y = y[index]\n",
        "\n",
        "# index = random.sample(range(0,length), int(length / 4))\n",
        "\n",
        "X = X[index]\n",
        "y = y[index]\n",
        "\n",
        "y = utils.to_categorical(y)\n",
        "\n",
        "print(X.shape)\n",
        "print(X[1])\n",
        "print(y[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sbAduiZryBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AQeHx4HBvv8O"
      },
      "source": [
        "###draw data distribution 1-6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BN1RgSLWvv8R",
        "colab": {}
      },
      "source": [
        "plt.hist(y, bins = 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lJUabvmyvv8e"
      },
      "source": [
        "###training 1-6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qahrtZ2yvv8i",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"stock_predict_3_1-6.h5\")\n",
        "\n",
        "history = model.fit(X, y, batch_size = 1024, epochs = 64,\\\n",
        "            validation_split = 0.1, shuffle = True, \\\n",
        "            # callbacks = [tbCallBack]\\\n",
        "            )\n",
        "plt.plot(history.history[\"acc\"])\n",
        "# plt.plot(history.history[\"loss\"])\n",
        "model.save_weights(\"stock_predict_3_1-6.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NCk527zzvv85"
      },
      "source": [
        "###drawing validation 1-6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xRPaKp41vv87",
        "colab": {}
      },
      "source": [
        "\n",
        "stock_qty = len(ts_code)\n",
        "\n",
        "index = np.random.randint(0, stock_qty)\n",
        "\n",
        "                      \n",
        "x_plot = []\n",
        "y_plot = []\n",
        "yy_plot = []\n",
        "\n",
        "stk_data = result[result.code == ts_code.iloc[index][\"code\"]]\n",
        "length = len(stk_data)\n",
        "if ((length - days_from_ipo - predict_next_days) > window_size):\n",
        "  for l in range(days_from_ipo, length - window_size - predict_next_days):\n",
        "    ohlct = stk_data.iloc[l : l + window_size + predict_next_days] \\\n",
        "        [[\"open\", \"high\", \"low\", \"close\", \"isST\",\"pctChg\"]].values\n",
        "    if np.all(ohlct[:, -2] != 1) and \\\n",
        "       np.all(ohlct[:,-1] > -10.0) and \\\n",
        "       np.all(ohlct[:,-1] < 10.0) :\n",
        "      min_price = ohlct[:-predict_next_days,:-2].min()\n",
        "      max_price = ohlct[:-predict_next_days,:-2].max()\n",
        "      scale = (max_price - min_price)\n",
        "      ohlct[:-predict_next_days,:-2] = ([ohlct[:-predict_next_days,:-2] - min_price]) /scale\n",
        "\n",
        "      x_plot.extend([np.expand_dims(ohlct[:-predict_next_days,:-2], axis = -1)])\n",
        "\n",
        "      # ohlct[-1,-1] = (ohlct[-1,-1] + 10.0) / 20.0\n",
        "      if ohlct[-predict_next_days,-1] <= -edge:\n",
        "        y_plot.append(0)\n",
        "      elif ohlct[-predict_next_days,-1] > -edge and \\\n",
        "        ohlct[-predict_next_days,-1] <= 0:\n",
        "        y_plot.append(1)\n",
        "      elif ohlct[-predict_next_days,-1] > 0 and \\\n",
        "        ohlct[-predict_next_days,-1] <= edge:\n",
        "        y_plot.append(2)\n",
        "      else:\n",
        "        y_plot.append(3)\n",
        "\n",
        "\n",
        "  X_plot = np.array(x_plot)\n",
        "  y_plot = np.array(y_plot)\n",
        "\n",
        "  # yy_plot = np.array(yy_plot)\n",
        "  print(ts_code.iloc[index])    \n",
        "\n",
        "else:\n",
        "  print(\"data too short, try again!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qWtYheSQvv9F",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"stock_predict_3_1-6.h5\")\n",
        "p = model.predict(X_plot)\n",
        "p = np.apply_along_axis(lambda d: d.argmax() + 1, 1, p)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(15,4.8))\n",
        "plt.plot(y_plot[-100:], color=\"blue\")\n",
        "plt.plot(p[-100:], color=\"red\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nenRGirXVbjw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.apply_along_axis(lambda d: d.argmax(), 1, p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jeq1O0RHvv9b",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"stock_predict_3_1-6.h5\")\n",
        "model.evaluate(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9ouV4-hQvv9o",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"stock_predict_3_1-6.h5\")\n",
        "\n",
        "model.evaluate(X_plot, utils.to_categorical(y_plot))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kKXBcctzvv95"
      },
      "source": [
        "###get data of specific code 1-6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kvEuGsM0vv98",
        "colab": {}
      },
      "source": [
        "s_code = \"sh.000016\"\n",
        "\n",
        "s_data_file = s_code + \"_1-6.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q46lAJ8Jvv-H",
        "colab": {}
      },
      "source": [
        "\n",
        "s_code = \"sh.000016\"\n",
        "\n",
        "s_data_file = s_code + \"_1-6.csv\"\n",
        "\n",
        "bs.login()\n",
        "\n",
        "rs = bs.query_history_k_data_plus(s_code, \",\".join(data_fields),\\\n",
        "                          start_date = start_date, end_date = end_date,\\\n",
        "                            frequency = \"d\", adjustflag = adjustflag)\n",
        "\n",
        "data_list = []\n",
        "while (rs.error_code == \"0\") and rs.next():\n",
        "    row_data = rs.get_row_data()\n",
        "    if(row_data[6] == \"1\"):         \n",
        "        data_list.append(row_data)\n",
        "s_result = pd.DataFrame(data_list, columns = rs.fields)\n",
        "s_result.to_csv(s_data_file)\n",
        "print(s_result.head())\n",
        "\n",
        "bs.logout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P8iDRzhCvv-S"
      },
      "source": [
        "###dataset of specific code 1-6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8vdO3VPbvv-W",
        "colab": {}
      },
      "source": [
        "edge = 3.0\n",
        "\n",
        "x = []\n",
        "y = []\n",
        "\n",
        "stk_data = pd.read_csv(s_data_file)\n",
        "length = len(stk_data)\n",
        "if ((length - days_from_ipo - predict_next_days) > window_size):\n",
        " for l in range(days_from_ipo, length - window_size - predict_next_days):\n",
        "  ohlct = stk_data.iloc[l : l + window_size + predict_next_days]\\\n",
        "          [[\"open\", \"high\", \"low\", \"close\", \"isST\", \"pctChg\"]].values\n",
        "  if np.all(ohlct[:, -2] != 1) and \\\n",
        "     np.all(ohlct[:,-1] > -10.0) and \\\n",
        "      np.all(ohlct[:,-1] < 10.0) :\n",
        "        max_price = ohlct[:-predict_next_days,:-2].max()\n",
        "  min_price = ohlct[:-predict_next_days,:-2].min()\n",
        "  scale = max_price - min_price\n",
        "  ohlct[:-predict_next_days,:-2] = ([ohlct[:-predict_next_days,:-2] - min_price]) /scale\n",
        "\n",
        "  x.append(np.expand_dims(ohlct[:-predict_next_days,:-2], axis=-1))\n",
        "\n",
        "  # y.extend([utils.to_categorical(ohlct[-1,-1], num_classes=201)])\n",
        "  # ohlct[-predict_next_days,-1] = (ohlct[-predict_next_days,-1] + 10.0) / 20.0\n",
        "  if ohlct[-predict_next_days,-1] <= -edge:\n",
        "    y.append(0)\n",
        "  elif ohlct[-predict_next_days,-1] > -edge and \\\n",
        "    ohlct[-predict_next_days,-1] <= 0:\n",
        "    y.append(1)\n",
        "  elif ohlct[-predict_next_days,-1] > 0 and \\\n",
        "    ohlct[-predict_next_days,-1] <= edge:\n",
        "    y.append(2)\n",
        "  else:\n",
        "    y.append(3)\n",
        "\n",
        "\n",
        "\n",
        "s_X = np.array(x)\n",
        "s_y = np.array(y)\n",
        "\n",
        "\n",
        "# upsample\n",
        "# dis = district\n",
        "\n",
        "dis_count, dis_edge = np.histogram(y, bins = 4)\n",
        "\n",
        "dis_count_max = dis_count.max()\n",
        "\n",
        "dis_count = dis_count_max/dis_count\n",
        "dis_count = dis_count.astype(int)\n",
        "\n",
        "time_count = np.apply_along_axis((lambda d: dis_count[d.astype(int)]), \\\n",
        "                                0 , s_y)\n",
        "\n",
        "s_X = np.repeat(s_X, time_count, axis = 0)\n",
        "s_y = np.repeat(s_y, time_count, axis = 0)\n",
        "\n",
        "\n",
        "#shuffle\n",
        "length = s_X.shape[0]\n",
        "\n",
        "index = np.arange(length)\n",
        "np.random.shuffle(index)\n",
        "\n",
        "s_X = s_X[index]\n",
        "s_y = s_y[index]\n",
        "\n",
        "# index = random.sample(range(0,length), int(length / 4))\n",
        "\n",
        "s_X = s_X[index]\n",
        "s_y = s_y[index]\n",
        "\n",
        "s_y = utils.to_categorical(s_y)\n",
        "\n",
        "print(s_X.shape)\n",
        "print(s_X[1])\n",
        "print(s_y[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cKV8H5ywvv-m"
      },
      "source": [
        "###training basing on model1-6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sCWut5rVvv-x",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"stock_predict_3_1-6.h5\")\n",
        "# model.load_weights(s_data_file + \".h5\")\n",
        "\n",
        "history = model.fit(s_X, s_y, batch_size = 128, epochs = 64,\\\n",
        "            validation_split = 0.1, shuffle = True, \\\n",
        "            # callbacks = [tbCallBack]\\\n",
        "            )\n",
        "plt.plot(history.history[\"acc\"])\n",
        "# plt.plot(history.history[\"loss\"])\n",
        "model.save_weights(s_data_file + \".h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3TdN1QEEvv-5"
      },
      "source": [
        "###get more data for specific code 1-6\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dG-1xYUVvv-7",
        "colab": {}
      },
      "source": [
        "bs.login()\n",
        "\n",
        "s_date = \"2018-06-01\"\n",
        "e_date = \"2019-11-13\"\n",
        "\n",
        "rs = bs.query_history_k_data_plus(s_code, \",\".join(data_fields),\\\n",
        "                          start_date = s_date, end_date = e_date,\\\n",
        "                            frequency = \"d\", adjustflag = adjustflag)\n",
        "\n",
        "data_list = []\n",
        "while (rs.error_code == \"0\") and rs.next():\n",
        "    row_data = rs.get_row_data()\n",
        "    if(row_data[6] == \"1\"):         \n",
        "        data_list.append(row_data)\n",
        "p_result = pd.DataFrame(data_list, columns = rs.fields)\n",
        "\n",
        "print(p_result.head())\n",
        "\n",
        "bs.logout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bW9oeSHVvv_B",
        "colab": {}
      },
      "source": [
        "print(p_result.loc[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wauhK0Ivvv_Q",
        "colab": {}
      },
      "source": [
        "print(p_result.count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jo_Nwseevv_d"
      },
      "source": [
        "###predict for specific code 1-6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GDITjuEOvv_f",
        "colab": {}
      },
      "source": [
        "                      \n",
        "x_plot = []\n",
        "y_plot = []\n",
        "\n",
        "stk_data = p_result\n",
        "length = len(stk_data)\n",
        "if ((length - predict_next_days) > window_size):\n",
        "  for l in range(length - window_size - predict_next_days):\n",
        "    ohlct = stk_data.iloc[l : l + window_size + predict_next_days] \\\n",
        "        [[\"open\", \"high\", \"low\", \"close\", \"isST\",\"pctChg\"]].values\n",
        "    ohlct = ohlct.astype(\"float\")\n",
        "    if np.all(ohlct[:, -2] != 1) and \\\n",
        "       np.all(ohlct[:,-1] > -10.0) and \\\n",
        "       np.all(ohlct[:,-1] < 10.0) :\n",
        "      min_price = ohlct[:-predict_next_days,:-2].min()\n",
        "      max_price = ohlct[:-predict_next_days,:-2].max()\n",
        "      scale = (max_price - min_price)\n",
        "      ohlct[:-predict_next_days,:-2] = ([ohlct[:-predict_next_days,:-2] - min_price]) /scale\n",
        "\n",
        "      x_plot.extend([np.expand_dims(ohlct[:-predict_next_days,:-2], axis = -1)])\n",
        "\n",
        "      # ohlct[-predict_next_days,-1] = (ohlct[-predict_next_days,-1] + 10.0) / 20.0\n",
        "      if ohlct[-predict_next_days,-1] <= -edge:\n",
        "        y_plot.append(0)\n",
        "      elif ohlct[-predict_next_days,-1] > -edge and \\\n",
        "        ohlct[-predict_next_days,-1] <= 0:\n",
        "        y_plot.append(1)\n",
        "      elif ohlct[-predict_next_days,-1] > 0 and \\\n",
        "        ohlct[-predict_next_days,-1] <= edge:\n",
        "        y_plot.append(2)\n",
        "      else:\n",
        "        y_plot.append(3)\n",
        "\n",
        "\n",
        "  X_plot = np.array(x_plot)\n",
        "  y_plot = np.array(y_plot)\n",
        "  # yy_plot = np.array(yy_plot)  \n",
        "\n",
        "else:\n",
        "  print(\"data too short, try again!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sz4sXwWZvv_n",
        "colab": {}
      },
      "source": [
        "model.load_weights(s_data_file + \".h5\")\n",
        "# model.load_weights(\"stock_predict_3_1-6.h5\")\n",
        "\n",
        "p = model.predict(X_plot)\n",
        "p = np.apply_along_axis(lambda d: d.argmax() + 1, 1, p)\n",
        "\n",
        "plt.figure(figsize=(15,4.8))\n",
        "plt.plot(y_plot, color=\"blue\")\n",
        "plt.plot(p, color=\"red\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVaJgFYXjOtL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(s_data_file + \".h5\")\n",
        "model.evaluate(X_plot, utils.to_categorical(y_plot))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fWGVoHUha_5",
        "colab_type": "text"
      },
      "source": [
        "##model 1-7: CNN + LSTM with dif params by crossentrpy for next few days"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRxx0fuVixHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_next_days = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KYH4j1hpiNGs",
        "colab": {}
      },
      "source": [
        "def make_model(summary = False):\n",
        "  K.clear_session()\n",
        "  # tf.keras.backend.clear_session()\n",
        "  p_lstm = 64\n",
        "\n",
        "  input = layers.Input(shape = (window_size, factor_num - 1 ,1))\n",
        "\n",
        "\n",
        "  model_1 = layers.Conv2D(64, kernel_size =(1,4))(input)\n",
        "  model_1 = layers.Activation(\"relu\")(model_1)\n",
        "  model_1 = layers.BatchNormalization()(model_1)\n",
        "  model_1 = layers.Dropout(0.5)(model_1)\n",
        "\n",
        "  model_1 = layers.Reshape((-1,64))(model_1)\n",
        "\n",
        "  model_1 = layers.LSTM(p_lstm)(model_1)\n",
        "\n",
        "\n",
        "\n",
        "  model_5 = layers.Conv2D(128, kernel_size =(5,4))(input)\n",
        "  model_5 = layers.Activation(\"relu\")(model_5)\n",
        "  model_5 = layers.BatchNormalization()(model_5)\n",
        "  model_5 = layers.Dropout(0.5)(model_5)\n",
        "\n",
        "  model_5 = layers.Reshape((-1,128))(model_5)\n",
        "\n",
        "  model_5 = layers.LSTM(p_lstm)(model_5)\n",
        "\n",
        "  model_10 = layers.Conv2D(256, kernel_size =(10,4))(input)\n",
        "  model_10 = layers.Activation(\"relu\")(model_10)\n",
        "  model_10 = layers.BatchNormalization()(model_10)\n",
        "  model_10 = layers.Dropout(0.5)(model_10)\n",
        "\n",
        "  model_10 = layers.Reshape((-1,256))(model_10)\n",
        "\n",
        "  model_10 = layers.LSTM(p_lstm)(model_10)\n",
        "\n",
        "  model_20 = layers.Conv2D(512, kernel_size =(20,4))(input)\n",
        "  model_20 = layers.Activation(\"relu\")(model_20)\n",
        "  model_20 = layers.BatchNormalization()(model_20)\n",
        "  model_20 = layers.Dropout(0.5)(model_20)\n",
        "\n",
        "  model_20 = layers.Reshape((-1,512))(model_20)\n",
        "\n",
        "  model_20 = layers.LSTM(p_lstm)(model_20)\n",
        "\n",
        "\n",
        "\n",
        "  model_30 = layers.Conv2D(1024, kernel_size =(30,4))(input)\n",
        "  model_30 = layers.Activation(\"relu\")(model_30)\n",
        "  model_30 = layers.BatchNormalization()(model_30)\n",
        "  model_30 = layers.Dropout(0.5)(model_30)\n",
        "\n",
        "  model_30 = layers.Reshape((-1,1024))(model_30)\n",
        "\n",
        "  model_30 = layers.LSTM(p_lstm)(model_30)\n",
        "\n",
        "\n",
        "\n",
        "  model = layers.concatenate([model_1, model_5, model_10, model_20, model_30], axis = -1)\n",
        "\n",
        "\n",
        "  model = layers.Dense(2048)(model)\n",
        "  model = layers.Activation(\"relu\")(model)\n",
        "  model = layers.BatchNormalization()(model)\n",
        "  model = layers.Dropout(0.5)(model)\n",
        "\n",
        "\n",
        "  model = layers.Dense(1024)(model)\n",
        "  model = layers.Activation(\"relu\")(model)\n",
        "  model = layers.BatchNormalization()(model)\n",
        "  model = layers.Dropout(0.5)(model)\n",
        "\n",
        "  model = layers.Dense(512)(model)\n",
        "  model = layers.Activation(\"relu\")(model)\n",
        "  model = layers.BatchNormalization()(model)\n",
        "  model = layers.Dropout(0.5)(model)\n",
        "\n",
        "  model = layers.Dense(256)(model)\n",
        "  model = layers.Activation(\"relu\")(model)\n",
        "  model = layers.BatchNormalization()(model)\n",
        "  model = layers.Dropout(0.5)(model)\n",
        "\n",
        "  model = layers.Dense(128)(model)\n",
        "  model = layers.Activation(\"relu\")(model)\n",
        "  model = layers.BatchNormalization()(model)\n",
        "  model = layers.Dropout(0.5)(model)\n",
        "\n",
        "  model = layers.Dense(64)(model)\n",
        "  model = layers.Activation(\"relu\")(model)\n",
        "  model = layers.BatchNormalization()(model)\n",
        "  model = layers.Dropout(0.5)(model)\n",
        "\n",
        "  model = layers.Dense(32)(model)\n",
        "  model = layers.Activation(\"relu\")(model)\n",
        "  model = layers.BatchNormalization()(model)\n",
        "  model = layers.Dropout(0.5)(model)\n",
        "\n",
        "  model = layers.Dense(4)(model)\n",
        "  model = layers.Activation(\"softmax\")(model)\n",
        "\n",
        "  model = Model(inputs = input, outputs = model)\n",
        "\n",
        "  # opt = optimizers.RMSprop(lr = 0.0005, decay = 0.001)\n",
        "  opt = optimizers.Adam(lr = 0.0005, decay = 0.001)\n",
        "\n",
        "  model.compile(loss = \"categorical_crossentropy\", optimizer = opt, metrics = [\"acc\"])\n",
        "\n",
        "  if summary:\n",
        "    model.summary()\n",
        "\n",
        "  return model\n",
        "\n",
        "model = make_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "V9ukse_8iNG1"
      },
      "source": [
        "###dataset 1-7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DY25BWpPiNG3",
        "colab": {}
      },
      "source": [
        "pct_of_stock  = 0.2\n",
        "stock_qty = len(ts_code)\n",
        "edge = 10.0\n",
        "\n",
        "index = random.sample(range(0,stock_qty), int(stock_qty*pct_of_stock))\n",
        "\n",
        "print(np.sort(index))\n",
        "                      \n",
        "x = []\n",
        "y = []\n",
        "\n",
        "count = 0\n",
        "\n",
        "for i in index:\n",
        "  count = count + 1\n",
        "  if count%200 == 0:\n",
        "    print(count)\n",
        "  stk_data = result[result.code == ts_code.iloc[i][\"code\"]]\n",
        "  length = len(stk_data)\n",
        "  if ((length - days_from_ipo - predict_next_days) > window_size):\n",
        "    for l in range(days_from_ipo, length - window_size - predict_next_days):\n",
        "      ohlct = stk_data.iloc[l : l + window_size + predict_next_days]\\\n",
        "          [[\"open\", \"high\", \"low\", \"close\", \"tradestatus\", \"isST\", \"pctChg\"]].values\n",
        "      if np.all(ohlct[:,-2] != 1) and \\\n",
        "        np.all(ohlct[:,-3] != 0) and \\\n",
        "       np.all(ohlct[:,-1] >= -10.0) and \\\n",
        "       np.all(ohlct[:,-1] <= 10.0) :\n",
        "        max_price = ohlct[:-predict_next_days,:-3].max()\n",
        "        min_price = ohlct[:-predict_next_days,:-3].min()\n",
        "        scale = max_price - min_price\n",
        "        ohlct[:-predict_next_days,:-3] = ([ohlct[:-predict_next_days,:-3] - min_price]) /scale\n",
        "\n",
        "        x.append(np.expand_dims(ohlct[:-predict_next_days,:-3], axis=-1))\n",
        "\n",
        "        next_days_pctChg = ohlct[-predict_next_days:,-1].sum()\n",
        "\n",
        "        if next_days_pctChg  <= -edge:\n",
        "          y.append(0)\n",
        "        elif next_days_pctChg  > -edge and \\\n",
        "          next_days_pctChg  <= 0:\n",
        "          y.append(1)\n",
        "        elif next_days_pctChg  > 0 and \\\n",
        "          next_days_pctChg  <= edge:\n",
        "          y.append(2)\n",
        "        else:\n",
        "          y.append(3)\n",
        "\n",
        "\n",
        "X = np.array(x)\n",
        "y = np.array(y)\n",
        "\n",
        "\n",
        "# upsample\n",
        "# dis = district\n",
        "\n",
        "dis_count, dis_edge = np.histogram(y, bins = 4)\n",
        "\n",
        "dis_count_max = dis_count.max()\n",
        "\n",
        "dis_count = dis_count + 1.0 #plus 1 to avoid devide by zero\n",
        "dis_count_max = dis_count_max + 1.0 #because dis_count plus 1 above, \n",
        "                    #here plus 1 to avoid time below to be zero\n",
        "\n",
        "time = dis_count_max/dis_count\n",
        "time = time.astype(int)\n",
        "\n",
        "time_count = np.apply_along_axis((lambda d: time[d.astype(int)]), \\\n",
        "                                0 , y)\n",
        "\n",
        "X = np.repeat(X, time_count, axis = 0)\n",
        "y = np.repeat(y, time_count, axis = 0)\n",
        "\n",
        "# shuffle dataset\n",
        "\n",
        "length = X.shape[0]\n",
        "\n",
        "r_index = np.arange(length)\n",
        "np.random.shuffle(r_index)\n",
        "\n",
        "X = X[r_index]\n",
        "y = y[r_index]\n",
        "\n",
        "# r_index = random.sample(range(0,length), int(length / 4))\n",
        "\n",
        "# X = X[r_index]\n",
        "# y = y[r_index]\n",
        "\n",
        "y = utils.to_categorical(y)\n",
        "\n",
        "print(X.shape)\n",
        "print(X[1])\n",
        "print(y[0])\n",
        "\n",
        "# X.tofile(\"stock_predict_3_1-7-X.dat\", format=\"%f\")\n",
        "# y.tofile(\"stock_predict_3_1-7-y.dat\", format=\"%f\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEVK7MxFVYRG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yy = y.argmax(axis = 1)\n",
        "\n",
        "if np.any(yy == 2): \n",
        "  print(\"ok\")\n",
        "\n",
        "# y[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XqH6I3rXiNHC"
      },
      "source": [
        "###draw data distribution 1-7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FqKw1LJRiNHF",
        "colab": {}
      },
      "source": [
        "plt.hist(y.argmax(axis = 1), bins = 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NtW_rDmOiNHJ"
      },
      "source": [
        "###training 1-7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iROmT0CUFj0-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oL9fSeR9EDbp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.fromfile(\"stock_predict_3_1-7-X.dat\", dtype=np.float).reshape(26654, 90, 4, 1)\n",
        "y = np.fromfile(\"stock_predict_3_1-7-y.dat\", dtype=np.float32).reshape(26654, 4)\n",
        "print(X[100])\n",
        "print(y[180])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4L_YQrb0iNHJ",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "model.load_weights(\"stock_predict_3_1-7.h5\")\n",
        "\n",
        "for t in range(20):\n",
        "  history = model.fit(X, y, batch_size = 1024, epochs = 4,\\\n",
        "              validation_split = 0.1, shuffle = True, \\\n",
        "              # callbacks = [tbCallBack]\\\n",
        "              )\n",
        "\n",
        "  model.save_weights(\"stock_predict_3_1-7.h5\")\n",
        "\n",
        "plt.plot(history.history[\"acc\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-zJ_Mpr6Jcr",
        "colab_type": "text"
      },
      "source": [
        "###training by generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsLfRnUL6R8S",
        "colab_type": "text"
      },
      "source": [
        "####define a generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJGGjQ6C6aYP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gntor(ts_data, ts_code, pct_of_stock=0.05, edge=10.0, batch_size = 512, generator = True):  \n",
        "\n",
        "  stock_qty = len(ts_code)\n",
        "  # index = random.sample(range(0,stock_qty), int(stock_qty*pct_of_stock))\n",
        "\n",
        "  while True :\n",
        "\n",
        "    index = random.sample(range(0,stock_qty), int(stock_qty*pct_of_stock))                   \n",
        "\n",
        "    # x = []\n",
        "    # y = []\n",
        "\n",
        "    for i in index:\n",
        "    # for i in range(stock_qty):\n",
        "\n",
        "      x = []\n",
        "      y = []\n",
        "\n",
        "      stk_data = ts_data[ts_data.code == ts_code.iloc[i][\"code\"]]\n",
        "      length = len(stk_data)\n",
        "      if ((length - days_from_ipo - predict_next_days) > window_size):\n",
        "        for l in range(days_from_ipo, length - window_size - predict_next_days):\n",
        "          ohlct = stk_data.iloc[l : l + window_size + predict_next_days]\\\n",
        "              [[\"open\", \"high\", \"low\", \"close\", \"tradestatus\", \"isST\", \"pctChg\"]].values.astype(\"float\")\n",
        "          if np.all(ohlct[:,-2] == 0) and \\\n",
        "            np.all(ohlct[:,-3] == 1) and \\\n",
        "          np.all(ohlct[:,-1] >= -10.0) and \\\n",
        "          np.all(ohlct[:,-1] <= 10.0) :\n",
        "            max_price = ohlct[:-predict_next_days,:-3].max()\n",
        "            min_price = ohlct[:-predict_next_days,:-3].min()\n",
        "            scale = max_price - min_price\n",
        "            ohlct[:-predict_next_days,:-3] = ([ohlct[:-predict_next_days,:-3] - min_price]) /scale\n",
        "\n",
        "            x.append(np.expand_dims(ohlct[:-predict_next_days,:-3], axis=-1))\n",
        "\n",
        "            next_days_pctChg = (ohlct[-1,-4] - ohlct[-predict_next_days,-4]) * 100 / ohlct[-predict_next_days,-4]\n",
        "\n",
        "            if next_days_pctChg  <= -edge:\n",
        "              y.append(0)\n",
        "            elif next_days_pctChg  > -edge and \\\n",
        "              next_days_pctChg  <= 0:\n",
        "              y.append(1)\n",
        "            elif next_days_pctChg  > 0 and \\\n",
        "              next_days_pctChg  <= edge:\n",
        "              y.append(2)\n",
        "            else:\n",
        "              y.append(3)\n",
        "    # print(\"there\")\n",
        "    if len(x) > 0:\n",
        "      # print(\"here\")\n",
        "      X = np.array(x)\n",
        "      y = np.array(y)\n",
        "\n",
        "      # upsample\n",
        "      # dis = district\n",
        "\n",
        "      dis_count, dis_edge = np.histogram(y, bins = 4, range=(0,3))\n",
        "\n",
        "      dis_count = dis_count + 1.0 #plus 1 to avoid devide by zero\n",
        "      dis_count_max = dis_count.max()\n",
        "\n",
        "      time = dis_count_max/dis_count\n",
        "      time = time.astype(int)\n",
        "\n",
        "      time_count = np.apply_along_axis((lambda d: time[d.astype(int)]), \\\n",
        "                                      0 , y)\n",
        "\n",
        "      X = np.repeat(X, time_count, axis = 0)\n",
        "      y = np.repeat(y, time_count, axis = 0)\n",
        "\n",
        "      # shuffle dataset\n",
        "\n",
        "      length = X.shape[0]\n",
        "\n",
        "      r_index = np.arange(length)\n",
        "      np.random.shuffle(r_index)\n",
        "\n",
        "      X = X[r_index]\n",
        "      y = y[r_index]\n",
        "\n",
        "      # r_index = random.sample(range(0,length), int(length / 4))\n",
        "\n",
        "      # X = X[r_index]\n",
        "      # y = y[r_index]\n",
        "\n",
        "      y = utils.to_categorical(y, num_classes=4)\n",
        "      if generator:\n",
        "        print(\"a\")\n",
        "        # for ll in range((length-1)//batch_size + 1):\n",
        "        #   start_i = ll*batch_size\n",
        "        #   end_i = start_i + batch_size\n",
        "        #   if end_i <= length:\n",
        "        #     yield(X[start_i:end_i],y[start_i:end_i])\n",
        "        #   else:\n",
        "        #     yield(X[start_i:],y[start_i:])\n",
        "      else:\n",
        "        return 1,2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1qdym0V2iqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i = random.randint(0,len(ts_code))\n",
        "print(i)\n",
        "stk_data = result[result.code == ts_code.iloc[i][\"code\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oEESjjS12jor"
      },
      "source": [
        "####define a generator 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dwMnoq0X2jot",
        "colab": {}
      },
      "source": [
        "def gntor_1(ts_data, ts_code, edge=10.0):\n",
        "  stock_qty = len(ts_code)\n",
        "\n",
        "  # print(np.sort(index))                        \n",
        "\n",
        "\n",
        "  while True:\n",
        "    i = random.randint(0,stock_qty-1)\n",
        "\n",
        "    x = []\n",
        "    y = []\n",
        "    # if count%1 == 0:\n",
        "    #   print(count)\n",
        "    stk_data = ts_data[ts_data.code == ts_code.iloc[i][\"code\"]]\n",
        "    length = len(stk_data)\n",
        "    if ((length - days_from_ipo - predict_next_days) > window_size):\n",
        "      for l in range(days_from_ipo, length - window_size - predict_next_days):\n",
        "        ohlct = stk_data.iloc[l : l + window_size + predict_next_days]\\\n",
        "            [[\"open\", \"high\", \"low\", \"close\", \"tradestatus\", \"isST\", \"pctChg\"]].values\n",
        "        if np.all(ohlct[:,-2] != 1) and \\\n",
        "          np.all(ohlct[:,-3] != 0) and \\\n",
        "        np.all(ohlct[:,-1] >= -10.0) and \\\n",
        "        np.all(ohlct[:,-1] <= 10.0) :\n",
        "          max_price = ohlct[:-predict_next_days,:-3].max()\n",
        "          min_price = ohlct[:-predict_next_days,:-3].min()\n",
        "          scale = max_price - min_price\n",
        "          ohlct[:-predict_next_days,:-3] = ([ohlct[:-predict_next_days,:-3] - min_price]) /scale\n",
        "\n",
        "          x.append(np.expand_dims(ohlct[:-predict_next_days,:-3], axis=-1))\n",
        "\n",
        "          next_days_pctChg = (ohlct[-1,-4] - ohlct[-predict_next_days,-4]) * 100 / ohlct[-predict_next_days,-4]\n",
        "\n",
        "          if next_days_pctChg  <= -edge:\n",
        "            y.append(0)\n",
        "          elif next_days_pctChg  > -edge and \\\n",
        "            next_days_pctChg  <= 0:\n",
        "            y.append(1)\n",
        "          elif next_days_pctChg  > 0 and \\\n",
        "            next_days_pctChg  <= edge:\n",
        "            y.append(2)\n",
        "          else:\n",
        "            y.append(3)\n",
        "\n",
        "      if len(x) > 0:\n",
        "        X = np.array(x)\n",
        "        y = np.array(y)\n",
        "\n",
        "        # upsample\n",
        "        # dis = district\n",
        "\n",
        "        dis_count, dis_edge = np.histogram(y, bins = 4)\n",
        "\n",
        "        dis_count_max = dis_count.max()\n",
        "\n",
        "        dis_count = dis_count + 1.0 #plus 1 to avoid devide by zero\n",
        "        dis_count_max = dis_count_max + 1.0 #because dis_count plus 1 above, \n",
        "                            #here plus 1 to avoid time below to be zero\n",
        "\n",
        "        time = dis_count_max/dis_count\n",
        "        time = time.astype(int)\n",
        "\n",
        "        time_count = np.apply_along_axis((lambda d: time[d.astype(int)]), \\\n",
        "                                        0 , y)\n",
        "\n",
        "        X = np.repeat(X, time_count, axis = 0)\n",
        "        y = np.repeat(y, time_count, axis = 0)\n",
        "\n",
        "        # shuffle dataset\n",
        "\n",
        "        length = X.shape[0]\n",
        "\n",
        "        r_index = np.arange(length)\n",
        "        np.random.shuffle(r_index)\n",
        "\n",
        "        X = X[r_index]\n",
        "        y = y[r_index]\n",
        "\n",
        "        # r_index = random.sample(range(0,length), int(length / 4))\n",
        "\n",
        "        # X = X[r_index]\n",
        "        # y = y[r_index]\n",
        "\n",
        "        y = utils.to_categorical(y, num_classes=4)\n",
        "\n",
        "        batch_size = 512\n",
        "        for ll in range((length-1)//batch_size + 1):\n",
        "          start_i = ll*batch_size\n",
        "          end_i = start_i + batch_size\n",
        "          if end_i <= length:\n",
        "            yield(X[start_i:end_i],y[start_i:end_i])\n",
        "          else:\n",
        "            yield(X[start_i:],y[start_i:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QP_3K0IJ8zH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(10000):\n",
        "  rr = gntor_1(result, ts_code, edge)\n",
        "  if i%1000 ==0:\n",
        "    print(i)\n",
        "    for ll in rr:\n",
        "      print(ll[0][0,0], ll[1][0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXwWmBX8-cNS",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "####training by generator 1-7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwEnxvBo-j-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "pct_of_stock  = 0.005\n",
        "stock_qty = len(ts_code)\n",
        "edge = 10.0\n",
        "\n",
        "step_num = int(stock_qty*pct_of_stock)\n",
        "\n",
        "model.load_weights(\"stock_predict_3_1-7.h5\")\n",
        "\n",
        "for i in range(20):\n",
        "  history = model.fit_generator(gntor(result, ts_code, pct_of_stock, edge, batch_size = 512), steps_per_epoch=step_num, epochs=1)\n",
        "  model.save_weights(\"stock_predict_3_1-7.h5\")\n",
        "\n",
        "plt.plot(history.history[\"acc\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTFLPfni28mC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "edge = 10.0\n",
        "\n",
        "model.load_weights(\"stock_predict_3_1-7.h5\")\n",
        "\n",
        "for i in range(20):\n",
        "  history = model.fit_generator(gntor_1(result, ts_code, edge), steps_per_epoch=50000, epochs=1)\n",
        "  model.save_weights(\"stock_predict_3_1-7.h5\")\n",
        "\n",
        "plt.plot(history.history[\"acc\"])\n",
        "# plt.plot(history.history[\"loss\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmOyk5_t-Wk6",
        "colab_type": "text"
      },
      "source": [
        "####define a generator like"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z-WdEIOh-cZ5",
        "colab": {}
      },
      "source": [
        "def gntor_like(ts_data, ts_code, pct_of_stock=0.05, edge=10.0):  \n",
        "\n",
        "  stock_qty = len(ts_code)\n",
        "\n",
        "  while True:\n",
        "    index = random.sample(range(0,stock_qty), int(stock_qty*pct_of_stock))\n",
        "    print(len(index))                   \n",
        "\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    for i in index:\n",
        "    # for i in range(stock_qty):\n",
        "\n",
        "      # x = []\n",
        "      # y = []\n",
        "\n",
        "      stk_data = ts_data[ts_data.code == ts_code.iloc[i][\"code\"]]\n",
        "      length = len(stk_data)\n",
        "      if ((length - days_from_ipo - predict_next_days) > window_size):\n",
        "        for l in range(days_from_ipo, length - window_size - predict_next_days):\n",
        "          ohlct = stk_data.iloc[l : l + window_size + predict_next_days]\\\n",
        "              [[\"open\", \"high\", \"low\", \"close\", \"tradestatus\", \"isST\", \"pctChg\"]].values.astype(\"float\")\n",
        "          if np.all(ohlct[:,-2] != 1) and \\\n",
        "            np.all(ohlct[:,-3] != 0) and \\\n",
        "          np.all(ohlct[:,-1] >= -10.0) and \\\n",
        "          np.all(ohlct[:,-1] <= 10.0) :\n",
        "            max_price = ohlct[:-predict_next_days,:-3].max()\n",
        "            min_price = ohlct[:-predict_next_days,:-3].min()\n",
        "            scale = max_price - min_price\n",
        "            ohlct[:-predict_next_days,:-3] = ([ohlct[:-predict_next_days,:-3] - min_price]) /scale\n",
        "\n",
        "            x.append(np.expand_dims(ohlct[:-predict_next_days,:-3], axis=-1))\n",
        "\n",
        "            next_days_pctChg = ohlct[-predict_next_days:,-1].sum()\n",
        "\n",
        "            if next_days_pctChg  <= -edge:\n",
        "              y.append(0)\n",
        "            elif next_days_pctChg  > -edge and \\\n",
        "              next_days_pctChg  <= 0:\n",
        "              y.append(1)\n",
        "            elif next_days_pctChg  > 0 and \\\n",
        "              next_days_pctChg  <= edge:\n",
        "              y.append(2)\n",
        "            else:\n",
        "              y.append(3)\n",
        "    # print(\"there\")\n",
        "    if len(x) > 0:\n",
        "      # print(\"here\")\n",
        "      X = np.array(x)\n",
        "      y = np.array(y)\n",
        "\n",
        "      # upsample\n",
        "      # dis = district\n",
        "\n",
        "      dis_count, dis_edge = np.histogram(y, bins = 4, range=(0,3))\n",
        "\n",
        "      dis_count = dis_count + 1.0 #plus 1 to avoid devide by zero\n",
        "      dis_count_max = dis_count.max()\n",
        "\n",
        "      time = dis_count_max/dis_count\n",
        "      time = time.astype(int)\n",
        "\n",
        "      time_count = np.apply_along_axis((lambda d: time[d.astype(int)]), \\\n",
        "                                      0 , y)\n",
        "\n",
        "      X = np.repeat(X, time_count, axis = 0)\n",
        "      y = np.repeat(y, time_count, axis = 0)\n",
        "\n",
        "      # shuffle dataset\n",
        "\n",
        "      # length = X.shape[0]\n",
        "\n",
        "      # r_index = np.arange(length)\n",
        "      # np.random.shuffle(r_index)\n",
        "\n",
        "      # X = X[r_index]\n",
        "      # y = y[r_index]\n",
        "\n",
        "      # r_index = random.sample(range(0,length), int(length / 4))\n",
        "\n",
        "      # X = X[r_index]\n",
        "      # y = y[r_index]\n",
        "\n",
        "      y = utils.to_categorical(y, num_classes=4)\n",
        "      return X, y\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k9yUCTn8-cZ-",
        "colab": {}
      },
      "source": [
        "X, y = gntor_like(result, ts_code, pct_of_stock, edge)\n",
        "print(X.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1VCwWp0M3Ez",
        "colab_type": "text"
      },
      "source": [
        "####define a generator like using class_weight"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xRcAlNbuMmcH",
        "colab": {}
      },
      "source": [
        "def gntor_like_cls_w(ts_data, ts_code, pct_of_stock=0.05, edge=10.0,\\\n",
        "                     index=[], shuffle = 0, y_cate = 1):  \n",
        "\n",
        "  stock_qty = len(ts_code)\n",
        "\n",
        "  while True:\n",
        "    if len(index) == 0:\n",
        "      index = random.sample(range(0,stock_qty), int(stock_qty*pct_of_stock))\n",
        "    \n",
        "    print(len(index))                   \n",
        "\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    for i in index:\n",
        "    # for i in range(stock_qty):\n",
        "\n",
        "      # x = []\n",
        "      # y = []\n",
        "\n",
        "      stk_data = ts_data[ts_data.code == ts_code.iloc[i][\"code\"]]\n",
        "      length = len(stk_data)\n",
        "      if ((length - days_from_ipo - predict_next_days) > window_size):\n",
        "        for l in range(days_from_ipo, length - window_size - predict_next_days):\n",
        "          ohlct = stk_data.iloc[l : l + window_size + predict_next_days]\\\n",
        "              [[\"open\", \"high\", \"low\", \"close\", \"tradestatus\", \"isST\", \"pctChg\"]].values.astype(\"float\")\n",
        "          if np.all(ohlct[:,-2] != 1) and \\\n",
        "            np.all(ohlct[:,-3] != 0) and \\\n",
        "          np.all(ohlct[:,-1] >= -10.1) and \\\n",
        "          np.all(ohlct[:,-1] <= 10.1) :\n",
        "            max_price = ohlct[:-predict_next_days,:-3].max()\n",
        "            min_price = ohlct[:-predict_next_days,:-3].min()\n",
        "            scale = max_price - min_price\n",
        "            ohlct[:-predict_next_days,:-3] = ([ohlct[:-predict_next_days,:-3] - min_price]) /scale\n",
        "\n",
        "            x.append(np.expand_dims(ohlct[:-predict_next_days,:-3], axis=-1))\n",
        "\n",
        "            # next_days_pctChg = ohlct[-predict_next_days:,-1].sum()  #wrong\n",
        "            next_days_pctChg = (ohlct[-1,-4] - ohlct[-predict_next_days,-4]) * 100 / ohlct[-predict_next_days,-4]\n",
        "\n",
        "            if next_days_pctChg  <= -edge:\n",
        "              y.append(0)\n",
        "            elif next_days_pctChg  <= 0:\n",
        "              y.append(1)\n",
        "            elif next_days_pctChg <= edge:\n",
        "              y.append(2)\n",
        "            else:\n",
        "              y.append(3)\n",
        "    # print(\"there\")\n",
        "    if len(x) > 0:\n",
        "      # print(\"here\")\n",
        "      X = np.array(x)\n",
        "      y = np.array(y)\n",
        "\n",
        "      # upsample\n",
        "      # dis = district\n",
        "\n",
        "      dis_count, dis_edge = np.histogram(y, bins = 4, range=(0,3))\n",
        "\n",
        "      dis_count = dis_count + 1.0 #plus 1 to avoid devide by zero\n",
        "      dis_count_max = dis_count.max()\n",
        "\n",
        "      time = dis_count_max/dis_count\n",
        "\n",
        "      # time = time.astype(int)\n",
        "\n",
        "      # time_count = np.apply_along_axis((lambda d: time[d.astype(int)]), \\\n",
        "      #                                 0 , y)\n",
        "\n",
        "      # X = np.repeat(X, time_count, axis = 0)\n",
        "      # y = np.repeat(y, time_count, axis = 0)\n",
        "\n",
        "      # shuffle dataset\n",
        "      if shuffle:\n",
        "        length = X.shape[0]\n",
        "\n",
        "        r_index = np.arange(length)\n",
        "        np.random.shuffle(r_index)\n",
        "\n",
        "        X = X[r_index]\n",
        "        y = y[r_index]\n",
        "\n",
        "      # r_index = random.sample(range(0,length), int(length / 4))\n",
        "\n",
        "      # X = X[r_index]\n",
        "      # y = y[r_index]\n",
        "\n",
        "      if y_cate:\n",
        "        y = utils.to_categorical(y, num_classes=4)\n",
        "      return X, y, time\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgEChfSCBMIA",
        "colab_type": "text"
      },
      "source": [
        "####trainning by generaor like 1-7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJLhOgd6BdSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pct_of_stock  = 0.1\n",
        "stock_qty = len(ts_code)\n",
        "edge = 10.0\n",
        "\n",
        "model.load_weights(\"stock_predict_3_1-7.h5\")\n",
        "\n",
        "for i in range(10):\n",
        "  X, y = gntor_like(result, ts_code, pct_of_stock, edge)\n",
        "  \n",
        "  print(datetime.datetime.today())\n",
        "\n",
        "  for l in range(10):\n",
        "    history = model.fit(X, y, batch_size = 1024, epochs = 10,\\\n",
        "                validation_split = 0.1, shuffle = True, \\\n",
        "                # callbacks = [tbCallBack]\\\n",
        "                ) \n",
        "\n",
        "    model.save_weights(\"stock_predict_3_1-7.h5\")\n",
        "\n",
        "plt.plot(history.history[\"acc\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "incI8NtA8Lp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t1, t2 = gntor(result, ts_code, pct_of_stock, edge, batch_size = 512, generator = False)\n",
        "print(t1, t2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3ZxQVErSrQO",
        "colab_type": "text"
      },
      "source": [
        "####trainning by generator like 1-7 using class_weight"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xwu_B3SS_04",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pct_of_stock  = 0.05\n",
        "stock_qty = len(ts_code)\n",
        "edge = 10.0\n",
        "\n",
        "model.load_weights(\"stock_predict_3_1-7.h5\")\n",
        "\n",
        "X, y, cls_weight = gntor_like_cls_w(result, ts_code, pct_of_stock, edge)\n",
        "\n",
        "for i in range(5):\n",
        "  \n",
        "  print(datetime.datetime.today())\n",
        "\n",
        "  for l in range(5):\n",
        "    history = model.fit(X, y, batch_size = 1024, epochs = 40,\\\n",
        "                validation_split = 0.1, shuffle = True, \\\n",
        "                class_weight = cls_weight,\\\n",
        "                # callbacks = [tbCallBack]\\\n",
        "                ) \n",
        "\n",
        "    model.save_weights(\"stock_predict_3_1-7.h5\")\n",
        "\n",
        "plt.plot(history.history[\"acc\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f15-DeZjU8ha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FIZeDUd339Cy"
      },
      "source": [
        "####trainning by generator like 1-7 using class_weight using specific set of ts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgvgNx7j4MjX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ts_list = [\"sh.600004\", \"sh.600352\", \"sh.601588\", \"sh.601111\", \"sz.000898\",\\\n",
        "       \"sh.601088\", \"sh.600368\", \"sz.002178\", \"sz.000761\", \"sh.600596\",\\\n",
        "       \"sz.300110\", \"sz.300308\", \"sz.000333\", \"sh.600588\", \"sh.600036\",\\\n",
        "       \"sz.002215\", \"sz.002353\", \"sz.002695\", \"sz.002422\", \"sz.000651\",\\\n",
        "       \"sz.002178\", \"sz.002023\", \"sz.300146\", \"sz.002001\", \"sz.300110\",\\\n",
        "       \"sz.000830\", \"sz.000157\"\n",
        "        ]\n",
        "\n",
        "ts_code = ts_code[~ts_code[\"code\"].isin(ts_list)]        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UWUQuQw4VKg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ts_code = ts_code[~ts_code[\"code\"].isin(ts_list)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSa7K-wB8KPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ts_code.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uuZd5EhXsRz",
        "colab_type": "text"
      },
      "source": [
        "####dataset preparing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrqizQgqK-Li",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#vaildation set\n",
        "\n",
        "ts_set = pd.DataFrame(ts_list, columns = [\"code\"])\n",
        "\n",
        "pct_of_stock  = 1\n",
        "stock_qty = len(ts_code)\n",
        "edge = 10.0\n",
        "\n",
        "X, y, cls_weight = gntor_like_cls_w(result, ts_set, pct_of_stock, edge, [], 1, 0)\n",
        "\n",
        "np.save(\"X-3-1-7-w.npy\", X)\n",
        "np.save(\"y-3-1-7-w.npy\", y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6TFl7ZJDNki",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#training set\n",
        "\n",
        "# pct_of_stock = 0.1\n",
        "pct_of_stock = 1\n",
        "edge = 10.0\n",
        "\n",
        "X1, y1, cls_weight = gntor_like_cls_w(result, ts_code[:1000], pct_of_stock, edge, [], 1, 0)\n",
        "# np.save(\"X-3-1-7-w1.npy\", X1)\n",
        "# np.save(\"y-3-1-7-w1.npy\", y1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWSjr0sPVqus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pct_of_stock = 1\n",
        "edge = 10.0\n",
        "\n",
        "X1, y1, cls_weight = gntor_like_cls_w(result, ts_code[:1000], pct_of_stock, edge, [], 1, 0)\n",
        "\n",
        "np.save(\"X-3-1-7-w1000.npy\", X1)\n",
        "np.save(\"y-3-1-7-w1000.npy\", y1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNPqO_57Vy7x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pct_of_stock = 1\n",
        "edge = 10.0\n",
        "\n",
        "X1, y1, cls_weight = gntor_like_cls_w(result, ts_code[1000:2000], pct_of_stock, edge, [], 1, 0)\n",
        "\n",
        "np.save(\"X-3-1-7-w2000.npy\", X1)\n",
        "np.save(\"y-3-1-7-w2000.npy\", y1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk5E0ngDV6vg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pct_of_stock = 1\n",
        "edge = 10.0\n",
        "\n",
        "X1, y1, cls_weight = gntor_like_cls_w(result, ts_code[2000:3000], pct_of_stock, edge, [], 1, 0)\n",
        "\n",
        "np.save(\"X-3-1-7-w3000.npy\", X1)\n",
        "np.save(\"y-3-1-7-w3000.npy\", y1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhUD9mHcWAIG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pct_of_stock = 1\n",
        "edge = 10.0\n",
        "\n",
        "X1, y1, cls_weight = gntor_like_cls_w(result, ts_code[3000:4000], pct_of_stock, edge, [], 1, 0)\n",
        "\n",
        "np.save(\"X-3-1-7-w4000.npy\", X1)\n",
        "np.save(\"y-3-1-7-w4000.npy\", y1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJUpdOI4X-fy",
        "colab_type": "text"
      },
      "source": [
        "####data set load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zT8Ovsz1ceJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(datetime.datetime.today())\n",
        "\n",
        "pct_of_stock = 0.1\n",
        "edge = 10.0\n",
        "v_split_pct = 0.2\n",
        "\n",
        "X = np.load(\"X-3-1-7-w.npy\")\n",
        "y = np.load(\"y-3-1-7-w.npy\")\n",
        "v_split = int(len(X) * (1-0.2))\n",
        "X_t = X[:v_split]\n",
        "X_v = X[v_split:]\n",
        "y_t = y[:v_split]\n",
        "y_v = y[v_split:]\n",
        "\n",
        "X1 = np.load(\"X-3-1-7-w1.npy\")\n",
        "y1 = np.load(\"y-3-1-7-w1.npy\")\n",
        "\n",
        "X_t = np.concatenate((X_t, X1), axis = 0)\n",
        "y_t = np.concatenate((y_t, y1), axis = 0)\n",
        "\n",
        "dis_count, dis_edge = np.histogram(y_t, bins = 4, range=(0,3))\n",
        "\n",
        "dis_count = dis_count + 1.0 #plus 1 to avoid devide by zero\n",
        "dis_count_max = dis_count.max()\n",
        "\n",
        "cls_weight = dis_count_max/dis_count\n",
        "# cls_weight = cls_weight / cls_weight.sum()\n",
        "\n",
        "cls_weight = dict(zip([0,1,2,3],cls_weight))\n",
        "\n",
        "y_t = utils.to_categorical(y_t, num_classes=4)\n",
        "y_v = utils.to_categorical(y_v, num_classes=4)\n",
        "\n",
        "\n",
        "\n",
        "print(datetime.datetime.today())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqElYGyXFvvm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(datetime.datetime.today())\n",
        "\n",
        "# pct_of_stock = 0.1\n",
        "# edge = 10.0\n",
        "v_split_pct = 0.2\n",
        "\n",
        "X1000 = np.load(\"X-3-1-7-w1000.npy\")\n",
        "y1000 = np.load(\"y-3-1-7-w1000.npy\")\n",
        "X2000 = np.load(\"X-3-1-7-w2000.npy\")  \n",
        "y2000 = np.load(\"y-3-1-7-w2000.npy\")\n",
        "# X3000 = np.load(\"X-3-1-7-w3000.npy\")\n",
        "# y3000 = np.load(\"y-3-1-7-w3000.npy\")\n",
        "# X4000 = np.load(\"X-3-1-7-w4000.npy\")\n",
        "# y4000 = np.load(\"y-3-1-7-w4000.npy\")\n",
        "\n",
        "\n",
        "X = np.load(\"X-3-1-7-w.npy\")\n",
        "y = np.load(\"y-3-1-7-w.npy\")\n",
        "v_split = int(len(X) * (1-v_split_pct))\n",
        "X_t = X[:v_split]\n",
        "X_v = X[v_split:]\n",
        "y_t = y[:v_split]\n",
        "y_v = y[v_split:]\n",
        "\n",
        "\n",
        "X_t = np.concatenate((X_t, \n",
        "                      X1000, \n",
        "                      X2000, \n",
        "                      # X3000, \n",
        "                      # X4000\n",
        "                      ), axis = 0)\n",
        "y_t = np.concatenate((y_t, \n",
        "                      y1000, \n",
        "                      y2000, \n",
        "                      # y3000, \n",
        "                      # y4000\n",
        "                      ), axis = 0)\n",
        "\n",
        "dis_count, dis_edge = np.histogram(y_t, bins = 4, range=(0,3))\n",
        "\n",
        "dis_count = dis_count + 1.0 #plus 1 to avoid devide by zero\n",
        "dis_count_max = dis_count.max()\n",
        "\n",
        "cls_weight = dis_count_max/dis_count\n",
        "# cls_weight = cls_weight / cls_weight.sum()\n",
        "\n",
        "cls_weight = dict(zip([0,1,2,3],cls_weight))\n",
        "\n",
        "y_t = utils.to_categorical(y_t, num_classes=4)\n",
        "y_v = utils.to_categorical(y_v, num_classes=4)\n",
        "\n",
        "\n",
        "\n",
        "print(datetime.datetime.today())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RHZZTa2sdib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(y_t.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwGP-23dUoKJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cls_weight = cls_weight / cls_weight.sum()\n",
        "print(cls_weight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dZBRMm3-oPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cls_weight = dict(zip([0,1,2,3],cls_weight))\n",
        "print(cls_weight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUNnRWjlHKE9",
        "colab_type": "text"
      },
      "source": [
        "####training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sEB7VSOu39C4",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "chk_point = ModelCheckpoint(filepath='stock_predict_3_1-7-set.h5')\n",
        "# model.load_weights(\"stock_predict_3_1-7-set.h5\")\n",
        "\n",
        "for i in range(8):\n",
        "\n",
        "  print(datetime.datetime.today())\n",
        "  model = make_model()\n",
        "  model.load_weights(\"stock_predict_3_1-7-set.h5\")\n",
        "  for l in range(2):\n",
        "    history = model.fit(X_t, y_t, batch_size = 1024, epochs = 20,\\\n",
        "                # validation_split = 0.1, shuffle = True, \\\n",
        "                class_weight = cls_weight,\\\n",
        "                validation_data = (X_v ,y_v),\\\n",
        "                # callbacks = [tbCallBack]\\\n",
        "                callbacks = [chk_point],\\\n",
        "                # initial_epoch = 5 \n",
        "                ) \n",
        "\n",
        "    model.save_weights(\"stock_predict_3_1-7-set.h5\")\n",
        "\n",
        "  model.save_weights(\"stock_predict_3_1-7-set_a.h5\")\n",
        "  del model\n",
        "  gc.collect()\n",
        "plt.plot(history.history[\"acc\"]) \n",
        "print(datetime.datetime.today())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kPT5JRyR39DH",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwNOB7RxxA5e",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnKqpXfOoUOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9b2gvH491q5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQi1AwMo_LoC",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BN8mbQlliNHU"
      },
      "source": [
        "###drawing validation 1-7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qIwL0cmpiNHW",
        "colab": {}
      },
      "source": [
        "\n",
        "stock_qty = len(ts_code)\n",
        "\n",
        "index = np.random.randint(0, stock_qty)\n",
        "\n",
        "                      \n",
        "x_plot = []\n",
        "y_plot = []\n",
        "yy_plot = []\n",
        "\n",
        "stk_data = result[result.code == ts_code.iloc[index][\"code\"]]\n",
        "length = len(stk_data)\n",
        "if ((length - days_from_ipo - predict_next_days) > window_size):\n",
        "  for l in range(days_from_ipo, length - window_size - predict_next_days):\n",
        "    ohlct = stk_data.iloc[l : l + window_size + predict_next_days] \\\n",
        "        [[\"open\", \"high\", \"low\", \"close\", \"isST\",\"pctChg\"]].values\n",
        "    if np.all(ohlct[:, -2] != 1) and \\\n",
        "       np.all(ohlct[:,-1] > -10.0) and \\\n",
        "       np.all(ohlct[:,-1] < 10.0) :\n",
        "      min_price = ohlct[:-predict_next_days,:-2].min()\n",
        "      max_price = ohlct[:-predict_next_days,:-2].max()\n",
        "      scale = (max_price - min_price)\n",
        "      ohlct[:-predict_next_days,:-2] = ([ohlct[:-predict_next_days,:-2] - min_price]) /scale\n",
        "\n",
        "      x_plot.extend([np.expand_dims(ohlct[:-predict_next_days,:-2], axis = -1)])\n",
        "\n",
        "\n",
        "      next_days_pctChg = ohlct[-predict_next_days:,-1].sum()\n",
        "\n",
        "      if next_days_pctChg  <= -edge:\n",
        "        y_plot.append(0)\n",
        "      elif next_days_pctChg  > -edge and \\\n",
        "        next_days_pctChg  <= 0:\n",
        "        y_plot.append(1)\n",
        "      elif next_days_pctChg  > 0 and \\\n",
        "        next_days_pctChg  <= edge:\n",
        "        y_plot.append(2)\n",
        "      else:\n",
        "        y_plot.append(3)\n",
        "\n",
        "\n",
        "\n",
        "  X_plot = np.array(x_plot)\n",
        "  y_plot = np.array(y_plot)\n",
        "\n",
        "  # yy_plot = np.array(yy_plot)\n",
        "  print(ts_code.iloc[index])    \n",
        "\n",
        "else:\n",
        "  print(\"data too short, try again!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jvs-gaKkiNHf",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"stock_predict_3_1-7.h5\")\n",
        "p = model.predict(X_plot)\n",
        "p = np.apply_along_axis(lambda d: d.argmax() + 1, 1, p)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(15,4.8))\n",
        "plt.plot(y_plot[-100:], color=\"blue\")\n",
        "plt.plot(p[-100:], color=\"red\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hNFADremiNHi",
        "colab": {}
      },
      "source": [
        "np.apply_along_axis(lambda d: d.argmax(), 1, p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ytjj8iN5iNHk",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"stock_predict_3_1-6.h5\")\n",
        "model.evaluate(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8-2eEeYniNHo",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"stock_predict_3_1-6.h5\")\n",
        "\n",
        "model.evaluate(X_plot, utils.to_categorical(y_plot))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "szBLpsH5iNHt"
      },
      "source": [
        "###get data of specific code 1-7\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZErhAkvHiNHt",
        "colab": {}
      },
      "source": [
        "s_code = \"sh.600004\"\n",
        "\n",
        "s_data_file = s_code + \"_1-7.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FB9ICGkaiNHw",
        "colab": {}
      },
      "source": [
        "\n",
        "s_code = \"sh.600004\"\n",
        "\n",
        "s_data_file = s_code + \"_1-7.csv\"\n",
        "\n",
        "bs.login()\n",
        "\n",
        "rs = bs.query_history_k_data_plus(s_code, \",\".join(data_fields),\\\n",
        "                          start_date = start_date, end_date = end_date,\\\n",
        "                            frequency = \"d\", adjustflag = adjustflag)\n",
        "\n",
        "data_list = []\n",
        "while (rs.error_code == \"0\") and rs.next():\n",
        "    row_data = rs.get_row_data()\n",
        "    if(row_data[6] == \"1\"):         \n",
        "        data_list.append(row_data)\n",
        "s_result = pd.DataFrame(data_list, columns = rs.fields)\n",
        "s_result.to_csv(s_data_file)\n",
        "print(s_result.head())\n",
        "\n",
        "bs.logout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ASbuU208iNHz"
      },
      "source": [
        "###dataset of specific code 1-7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c9MrDiHYiNH1",
        "colab": {}
      },
      "source": [
        "edge = 10.0\n",
        "\n",
        "x = []\n",
        "y = []\n",
        "\n",
        "stk_data = pd.read_csv(s_data_file)\n",
        "length = len(stk_data)\n",
        "if ((length - days_from_ipo - predict_next_days) > window_size):\n",
        " for l in range(days_from_ipo, length - window_size - predict_next_days):\n",
        "  ohlct = stk_data.iloc[l : l + window_size + predict_next_days]\\\n",
        "          [[\"open\", \"high\", \"low\", \"close\", \"isST\", \"pctChg\"]].values\n",
        "  if np.all(ohlct[:, -2] != 1) and \\\n",
        "     np.all(ohlct[:,-1] > -10.0) and \\\n",
        "      np.all(ohlct[:,-1] < 10.0) :\n",
        "        max_price = ohlct[:-predict_next_days,:-2].max()\n",
        "  min_price = ohlct[:-predict_next_days,:-2].min()\n",
        "  scale = max_price - min_price\n",
        "  ohlct[:-predict_next_days,:-2] = ([ohlct[:-predict_next_days,:-2] - min_price]) /scale\n",
        "\n",
        "  x.append(np.expand_dims(ohlct[:-predict_next_days,:-2], axis=-1))\n",
        "\n",
        "  # y.extend([utils.to_categorical(ohlct[-1,-1], num_classes=201)])\n",
        "  # ohlct[-predict_next_days,-1] = (ohlct[-predict_next_days,-1] + 10.0) / 20.0\n",
        "  next_days_pctChg = ohlct[-predict_next_days:,-1].sum()\n",
        "\n",
        "  if next_days_pctChg  <= -edge:\n",
        "    y.append(0)\n",
        "  elif next_days_pctChg  > -edge and \\\n",
        "    next_days_pctChg  <= 0:\n",
        "    y.append(1)\n",
        "  elif next_days_pctChg  > 0 and \\\n",
        "    next_days_pctChg  <= edge:\n",
        "    y.append(2)\n",
        "  else:\n",
        "    y.append(3)\n",
        "\n",
        "\n",
        "\n",
        "s_X = np.array(x)\n",
        "s_y = np.array(y)\n",
        "\n",
        "\n",
        "# upsample\n",
        "# dis = district\n",
        "\n",
        "dis_count, dis_edge = np.histogram(y, bins = 4)\n",
        "\n",
        "dis_count_max = dis_count.max()\n",
        "\n",
        "dis_count = dis_count_max/dis_count\n",
        "dis_count = dis_count.astype(int)\n",
        "\n",
        "time_count = np.apply_along_axis((lambda d: dis_count[d.astype(int)]), \\\n",
        "                                0 , s_y)\n",
        "\n",
        "s_X = np.repeat(s_X, time_count, axis = 0)\n",
        "s_y = np.repeat(s_y, time_count, axis = 0)\n",
        "\n",
        "\n",
        "#shuffle\n",
        "length = s_X.shape[0]\n",
        "\n",
        "index = np.arange(length)\n",
        "np.random.shuffle(index)\n",
        "\n",
        "s_X = s_X[index]\n",
        "s_y = s_y[index]\n",
        "\n",
        "# index = random.sample(range(0,length), int(length / 4))\n",
        "\n",
        "s_X = s_X[index]\n",
        "s_y = s_y[index]\n",
        "\n",
        "s_y = utils.to_categorical(s_y)\n",
        "\n",
        "print(s_X.shape)\n",
        "print(s_X[1])\n",
        "print(s_y[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nsEa0VvSiNH5"
      },
      "source": [
        "###training basing on model1-7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ENAkiw8GiNH6",
        "colab": {}
      },
      "source": [
        "# model.load_weights(\"stock_predict_3_1-7.h5\")\n",
        "model.load_weights(s_data_file + \".h5\")\n",
        "\n",
        "history = model.fit(s_X, s_y, batch_size = 128, epochs = 64,\\\n",
        "            validation_split = 0.1, shuffle = True, \\\n",
        "            # callbacks = [tbCallBack]\\\n",
        "            )\n",
        "plt.plot(history.history[\"acc\"])\n",
        "# plt.plot(history.history[\"loss\"])\n",
        "model.save_weights(s_data_file + \".h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VYmf-CfEiNIB"
      },
      "source": [
        "###get more data for specific code 1-7\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j1ioEmf6iNIC",
        "colab": {}
      },
      "source": [
        "s_code = \"sz.002064\"\n",
        "\n",
        "bs.login()\n",
        "\n",
        "s_date = \"2019-07-01\"\n",
        "e_date = \"2020-09-11\"\n",
        "\n",
        "rs = bs.query_history_k_data_plus(s_code, \",\".join(data_fields),\\\n",
        "                          start_date = s_date, end_date = e_date,\\\n",
        "                            frequency = \"d\", adjustflag = adjustflag)\n",
        "\n",
        "data_list = []\n",
        "while (rs.error_code == \"0\") and rs.next():\n",
        "    row_data = rs.get_row_data()\n",
        "    if(row_data[6] == \"1\"):         \n",
        "        data_list.append(row_data)\n",
        "p_result = pd.DataFrame(data_list, columns = rs.fields)\n",
        "\n",
        "print(p_result.head())\n",
        "print(p_result.tail())\n",
        "\n",
        "bs.logout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IIeRKqoMiNIE",
        "colab": {}
      },
      "source": [
        "print(p_result.loc[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tHnZibUYiNIJ",
        "colab": {}
      },
      "source": [
        "print(p_result.count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cp1z1px9Qi6w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(p_result[190:210]['close'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkaEWpKUOPkF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(12,4.8))\n",
        "plt.plot(p_result['close'].values.astype(\"float\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEzSEPJOfO-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(12,4.8))\n",
        "plt.plot(p_result['pctChg'].values.astype(\"float\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uhGFJpl_iNIN"
      },
      "source": [
        "###predict for specific code 1-7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FhLSAQ7CiNIO",
        "colab": {}
      },
      "source": [
        "edge = 10.0\n",
        "                      \n",
        "x_plot = []\n",
        "y_plot = []\n",
        "\n",
        "stk_data = p_result\n",
        "length = len(stk_data)\n",
        "if ((length - predict_next_days) > window_size):\n",
        "  for l in range(length - window_size - predict_next_days):\n",
        "\n",
        "    ohlct = stk_data.iloc[l : l + window_size + predict_next_days]\\\n",
        "    [[\"open\", \"high\", \"low\", \"close\", \"tradestatus\",\\\n",
        "      \"isST\", \"pctChg\"]].values.astype(\"float\")\n",
        "    if np.all(ohlct[:,-2] != 1) and \\\n",
        "      np.all(ohlct[:,-3] != 0) and \\\n",
        "    np.all(ohlct[:,-1] >= -10.1) and \\\n",
        "    np.all(ohlct[:,-1] <= 10.1) :\n",
        "      max_price = ohlct[:-predict_next_days,:-3].max()\n",
        "      min_price = ohlct[:-predict_next_days,:-3].min()\n",
        "      scale = max_price - min_price\n",
        "      ohlct[:-predict_next_days,:-3] = ([ohlct[:-predict_next_days,:-3] - min_price]) /scale\n",
        "\n",
        "      x_plot.extend([np.expand_dims(ohlct[:-predict_next_days,:-3], axis = -1)])\n",
        "\n",
        "      # next_days_pctChg = ohlct[-predict_next_days:,-1].sum()\n",
        "      next_days_pctChg = (ohlct[-1,-4] - ohlct[-predict_next_days,-4]) * 100 / ohlct[-predict_next_days,-4]\n",
        "\n",
        "      if next_days_pctChg  <= -edge:\n",
        "        y_plot.append(0)\n",
        "      elif next_days_pctChg <= 0:\n",
        "        y_plot.append(1)\n",
        "      elif next_days_pctChg <= edge:\n",
        "        y_plot.append(2)\n",
        "      else:\n",
        "        y_plot.append(3)\n",
        "\n",
        "\n",
        "  X_plot = np.array(x_plot)\n",
        "  y_plot = np.array(y_plot)\n",
        "  # yy_plot = np.array(yy_plot)  \n",
        "\n",
        "else:\n",
        "  print(\"data too short, try again!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owqZQ4p7ICY1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_plot.max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qyYHaVJdiNIR",
        "colab": {}
      },
      "source": [
        "# model.load_weights(s_data_file + \".h5\")\n",
        "# model.load_weights(\"stock_predict_3_1-6.h5\")\n",
        "model.load_weights(\"stock_predict_3_1-7-set.h5\")\n",
        "\n",
        "p = model.predict(X_plot)\n",
        "p = np.apply_along_axis(lambda d: d.argmax() + 1, 1, p)\n",
        "\n",
        "plt.figure(figsize=(15,4.8))\n",
        "plt.plot(y_plot, color=\"blue\")\n",
        "plt.plot(p, color=\"red\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruLtDQWal0p9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate(X_plot[-180:], utils.to_categorical(y_plot[-180:], num_classes=4) )\n",
        "# model.evaluate(X_plot, utils.to_categorical(y_plot, num_classes=4) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfVIVRZYl8m-",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QsGAjV9-iNIW",
        "colab": {}
      },
      "source": [
        "model.load_weights(s_data_file + \".h5\")\n",
        "model.evaluate(X_plot, utils.to_categorical(y_plot))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKmHj-mc0vGR",
        "colab_type": "text"
      },
      "source": [
        "###predict1-7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBjNsl7X0zAR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bs.login()\n",
        "\n",
        "ss_date = \"2018-06-01\"\n",
        "ee_date = \"2019-10-30\"\n",
        "\n",
        "# ss_code = \"sh.600004\"\n",
        "ss_code = \"sz.000717\"\n",
        "\n",
        "rs = bs.query_history_k_data_plus(ss_code, \",\".join(data_fields),\\\n",
        "                          start_date = ss_date, end_date = ee_date,\\\n",
        "                            frequency = \"d\", adjustflag = adjustflag)\n",
        "\n",
        "data_list = []\n",
        "while (rs.error_code == \"0\") and rs.next():\n",
        "    row_data = rs.get_row_data()\n",
        "    if(row_data[6] == \"1\"):         \n",
        "        data_list.append(row_data)\n",
        "pp_result = pd.DataFrame(data_list, columns = rs.fields)\n",
        "\n",
        "print(pp_result.head())\n",
        "\n",
        "bs.logout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUuNOI491P9T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_plot = []\n",
        "y_plot = []\n",
        "\n",
        "stk_data = pp_result\n",
        "length = len(stk_data)\n",
        "if (length > window_size):\n",
        "  for l in range(length - window_size):\n",
        "    ohlct = stk_data.iloc[l : l + window_size] \\\n",
        "        [[\"open\", \"high\", \"low\", \"close\", \"isST\",\"pctChg\"]].values\n",
        "    ohlct = ohlct.astype(\"float\")\n",
        "    if np.all(ohlct[:, -2] != 1) and \\\n",
        "       np.all(ohlct[:,-1] > -10.0) and \\\n",
        "       np.all(ohlct[:,-1] < 10.0) :\n",
        "      min_price = ohlct[:,:-2].min()\n",
        "      max_price = ohlct[:,:-2].max()\n",
        "      scale = (max_price - min_price)\n",
        "      ohlct[:,:-2] = ([ohlct[:,:-2] - min_price]) /scale\n",
        "\n",
        "      x_plot.extend([np.expand_dims(ohlct[:,:-2], axis = -1)])\n",
        "\n",
        "  XX_plot = np.array(x_plot)\n",
        "\n",
        "\n",
        "else:\n",
        "  print(\"data too short, try again!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfX2iJ_p1lq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.load_weights(s_data_file + \".h5\")\n",
        "model.load_weights(\"stock_predict_3_1-7.h5\")\n",
        "\n",
        "p = model.predict(XX_plot[-40:])\n",
        "p = np.apply_along_axis(lambda d: d.argmax() + 1, 1, p)\n",
        "\n",
        "plt.figure(figsize=(15,4.8))\n",
        "plt.plot(y_plot, color=\"blue\")\n",
        "plt.plot(p, color=\"red\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAsGTqSIlZwS",
        "colab_type": "text"
      },
      "source": [
        "#model 2: LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxoK7Xn8ll45",
        "colab_type": "text"
      },
      "source": [
        "##model 2-1: LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSjx6XIglpZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "K.clear_session()\n",
        "input = layers.Input(shape = (window_size, factor_num -1 )) #turn is not involved\n",
        "model = layers.LSTM(64, input_shape = (window_size, factor_num - 1), \\\n",
        "                    return_sequences = True)(input)\n",
        "# # model = layers.LSTM(64, return_sequences = True)(model)\n",
        "model = layers.Acvtivation(\"relu\")(model)\n",
        "model = layers.BatchNormalization()(model)\n",
        "model = layers.Dropout(0.5)(model)\n",
        "\n",
        "model = layers.LSTM(32)(model)\n",
        "model = layers.Acvtivation(\"relu\")(model)\n",
        "model = layers.BatchNormalization()(model)\n",
        "model = layers.Dropout(0.5)(model)\n",
        "\n",
        "model = layers.Dense(32)(model)\n",
        "model = layers.Acvtivation(\"relu\")(model)\n",
        "model = layers.BatchNormalization()(model)\n",
        "model = layers.Dropout(0.5)(model)\n",
        "\n",
        "model = layers.Dense(16)(model)\n",
        "model = layers.Acvtivation(\"relu\")(model)\n",
        "model = layers.BatchNormalization()(model)\n",
        "model = layers.Dropout(0.5)(model)\n",
        "\n",
        "model = layers.Dense(8)(model)\n",
        "model = layers.Acvtivation(\"relu\")(model)\n",
        "model = layers.BatchNormalization()(model)\n",
        "model = layers.Dropout(0.5)(model)\n",
        "\n",
        "model = layers.Dense(1)(model)\n",
        "\n",
        "model = Model(inputs = input, outputs = model)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "optimizer = optimizers.RMSprop(lr = 0.005, decay = 1e-5)\n",
        "\n",
        "model.compile(loss = \"mse\", optimizer = optimizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QXDMeMBn0h6",
        "colab_type": "text"
      },
      "source": [
        "###dataset 2-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofs8O4q7oF1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "pct_of_stock  = 0.004\n",
        "stock_qty = len(ts_code)\n",
        "\n",
        "index = random.sample(range(0,stock_qty), int(stock_qty*pct_of_stock))\n",
        "\n",
        "print(np.sort(index))\n",
        "                      \n",
        "x = []\n",
        "y = []\n",
        "\n",
        "for i in index:\n",
        "  stk_data = result[result.code == ts_code.iloc[i][\"code\"]]\n",
        "  length = len(stk_data)\n",
        "  if ((length - days_from_ipo - predict_next_days) > window_size):\n",
        "    for l in range(days_from_ipo, length - window_size - predict_next_days):\n",
        "      ohlct = stk_data.iloc[l : l + window_size + predict_next_days]\\\n",
        "          [[\"open\", \"high\", \"low\", \"close\", \"isST\", \"pctChg\"]].values\n",
        "      if np.all(ohlct[:, -2] != 1) and \\\n",
        "       np.all(ohlct[:,-1] > -10.0) and \\\n",
        "       np.all(ohlct[:,-1] < 10.0) :\n",
        "        max_price = ohlct[:-predict_next_days,:-2].max()\n",
        "        min_price = ohlct[:-predict_next_days,:-2].min()\n",
        "        scale = max_price - min_price\n",
        "        ohlct[:-predict_next_days,:-2] = ([ohlct[:-predict_next_days,:-2] - min_price]) /scale\n",
        "\n",
        "        x.append(ohlct[:-predict_next_days,:-2])\n",
        "\n",
        "        ohlct[-predict_next_days,-1] = (ohlct[-predict_next_days,-1] + 10.0) / 20.0\n",
        "        y.append(ohlct[-predict_next_days,-1])\n",
        "\n",
        "\n",
        "\n",
        "X = np.array(x)\n",
        "y = np.array(y)\n",
        "\n",
        "\n",
        "# upsample\n",
        "# dis = district\n",
        "dis_count, dis_edge = np.histogram(y, bins = 20)\n",
        "\n",
        "dis_count_max = dis_count.max() * 4\n",
        "\n",
        "dis_count = dis_count_max/dis_count\n",
        "dis_count = dis_count.astype(int)\n",
        "\n",
        "time_count = np.apply_along_axis((lambda d: dis_count[(d*100//5).astype(int)]), \\\n",
        "                                0 , y)\n",
        "\n",
        "X = np.repeat(X, time_count, axis = 0)\n",
        "y = np.repeat(y, time_count, axis = 0)\n",
        "\n",
        "length = X.shape[0]\n",
        "\n",
        "index = np.arange(length)\n",
        "np.random.shuffle(index)\n",
        "\n",
        "X = X[index]\n",
        "y = y[index]\n",
        "\n",
        "index = random.sample(range(0,length), int(length / 4))\n",
        "\n",
        "X = X[index]\n",
        "y = y[index]\n",
        "\n",
        "print(X.shape)\n",
        "print(X[1])\n",
        "print(y[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJVW4-P93844",
        "colab_type": "text"
      },
      "source": [
        "#Predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6ZDA4D_Jw0l",
        "colab_type": "text"
      },
      "source": [
        "##contants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXQ3phe1gj0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s_data_file = \"sh.600004\" + \"_1-7.csv\"\n",
        "pstart_date = \"2019-03-01\"\n",
        "pend_date = \"2019-10-25\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkuQIxtaJ7jr",
        "colab_type": "text"
      },
      "source": [
        "##load ts_code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3pIPHpwKAz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ts_code = pd.read_csv(ts_code_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaQQSrknNZOb",
        "colab_type": "text"
      },
      "source": [
        "##*get* data in specific period"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upHl1WCa4NDU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "17c61873-f184-44b9-8f78-1a6ac0a5d44f"
      },
      "source": [
        "data_list = []\n",
        "\n",
        "\n",
        "bs.login()\n",
        "for i in range(len(ts_code)):\n",
        "  if i%500 == 0 :\n",
        "    print(i)\n",
        "  rs = bs.query_history_k_data_plus(ts_code.iloc[i][\"code\"], \",\".join(data_fields),\\\n",
        "                              start_date = pstart_date, end_date = pend_date,\\\n",
        "                               frequency = \"d\", adjustflag = adjustflag)\n",
        "\n",
        "\n",
        "  while (rs.error_code == \"0\") and rs.next():\n",
        "    row_data = rs.get_row_data()\n",
        "    if(row_data[6] == \"1\"):         \n",
        "          data_list.append(row_data)\n",
        "\n",
        "bs.logout()\n",
        "\n",
        "presult = pd.DataFrame(data_list, columns = rs.fields)\n",
        "print(presult.head())\n",
        "print(presult.tail())\n",
        "print(presult.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "login success!\n",
            "0\n",
            "500\n",
            "1000\n",
            "1500\n",
            "2000\n",
            "2500\n",
            "3000\n",
            "3500\n",
            "logout success!\n",
            "             open            high             low  ... tradestatus isST       code\n",
            "0  112.0159840200  114.3871945200  110.0241672000  ...           1    0  sh.600000\n",
            "1  114.9562850400  117.4223439600  113.3438619000  ...           1    0  sh.600000\n",
            "2  113.9129524200  114.1974976800  112.5850745400  ...           1    0  sh.600000\n",
            "3  113.7232555800  115.2408303000  112.4902261200  ...           1    0  sh.600000\n",
            "4  114.1026492600  114.1974976800  112.5850745400  ...           1    0  sh.600000\n",
            "\n",
            "[5 rows x 9 columns]\n",
            "                  open            high  ... isST       code\n",
            "575136  368.9718880000  370.4658230900  ...    0  sz.300782\n",
            "575137  363.0262268700  380.0009390000  ...    0  sz.300782\n",
            "575138  378.9982980000  378.9982980000  ...    0  sz.300782\n",
            "575139  358.9454780000  366.7460249800  ...    0  sz.300782\n",
            "575140  354.9349140000  365.9639650000  ...    0  sz.300782\n",
            "\n",
            "[5 rows x 9 columns]\n",
            "575141\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVbI0AWZz64w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "db9da453-00ea-4c8d-9600-0ee487062220"
      },
      "source": [
        "presult[presult.code == \"sh.600526\"].iloc[-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "open           15.6064688000\n",
              "high           15.6364812400\n",
              "low            15.4263941600\n",
              "close          15.6364812400\n",
              "turn                0.244600\n",
              "pctChg              0.192300\n",
              "tradestatus                1\n",
              "isST                       1\n",
              "code               sh.600526\n",
              "Name: 67543, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p09S-yNaQdIG",
        "colab_type": "text"
      },
      "source": [
        "##predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKOVw9tMJrzd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "3be2713c-7f19-4871-de27-4c30e295394a"
      },
      "source": [
        "ts = []\n",
        "pp = []\n",
        "\n",
        "# model.load_weights(s_data_file + \".h5\")\n",
        "model.load_weights(\"stock_predict_3_1-7.h5\")\n",
        "\n",
        "for i in range(len(ts_code)):\n",
        "  if i%500 == 0:\n",
        "    print(i)\n",
        "  x = []\n",
        "  stk_data = presult[presult.code == ts_code.iloc[i][\"code\"]]\n",
        "  length = len(stk_data)\n",
        "  if length >= window_size :\n",
        "    # for l in range(length - window_size):\n",
        "    ohlct = stk_data.iloc[length - window_size : length]\\\n",
        "        [[\"open\", \"high\", \"low\", \"close\", \"tradestatus\", \"isST\", \"pctChg\"]].values.astype(\"float\")\n",
        "    if np.all(ohlct[:, -2] != 1) and \\\n",
        "      np.all(ohlct[:,-3] != 0) and \\\n",
        "      np.all(ohlct[:,-1] >= -10.0) and \\\n",
        "      np.all(ohlct[:,-1] <= 10.0) :\n",
        "      max_price = ohlct[:,:-3].max()\n",
        "      min_price = ohlct[:,:-3].min()\n",
        "      scale = max_price - min_price\n",
        "      ohlct[:,:-3] = ([ohlct[:,:-3] - min_price]) /scale\n",
        "\n",
        "      x.append(np.expand_dims(ohlct[:,:-3], axis=-1))\n",
        "\n",
        "    if len(x) > 0:\n",
        "      pX = np.array([x[-1]])\n",
        "      # print(pX.shape)\n",
        "      p = model.predict(pX)      \n",
        "      if p[-1].argmax() == 3 and p[-1,3] > 0.995:\n",
        "        ts.append(ts_code.iloc[i][\"code\"])\n",
        "        pp.append(p[-1])\n",
        "\n",
        "print(ts)\n",
        "print(len(ts))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "500\n",
            "1000\n",
            "1500\n",
            "2000\n",
            "2500\n",
            "3000\n",
            "3500\n",
            "['sh.600009', 'sh.600208', 'sh.600262', 'sh.600271', 'sh.600312', 'sh.600339', 'sh.600436', 'sh.600516', 'sh.600616', 'sh.600633', 'sh.600642', 'sh.600653', 'sh.601900', 'sh.601985', 'sh.603165', 'sh.603444', 'sh.603650', 'sh.603658', 'sh.603757', 'sh.603828', 'sz.000100', 'sz.000403', 'sz.000597', 'sz.000761', 'sz.000932', 'sz.000999', 'sz.001965', 'sz.002148', 'sz.002322', 'sz.002335', 'sz.002545', 'sz.002558', 'sz.002583', 'sz.002588', 'sz.002594', 'sz.002634', 'sz.002706', 'sz.002721', 'sz.002805', 'sz.002912', 'sz.002932', 'sz.002940', 'sz.300192', 'sz.300226', 'sz.300246', 'sz.300393', 'sz.300421', 'sz.300558', 'sz.300572', 'sz.300759']\n",
            "50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E40kbJsKsKNE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "outputId": "44c43377-4fe6-4bec-ef4a-835b9318ae0f"
      },
      "source": [
        "for i in range(len(ts)):\n",
        "  if(pp[i][3]) > 0.998:\n",
        "    print(ts[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sh.600009\n",
            "sh.600208\n",
            "sh.600262\n",
            "sh.600271\n",
            "sh.600339\n",
            "sh.600436\n",
            "sh.600516\n",
            "sh.600616\n",
            "sh.600633\n",
            "sh.601900\n",
            "sh.601985\n",
            "sh.603444\n",
            "sh.603650\n",
            "sh.603757\n",
            "sh.603828\n",
            "sz.000100\n",
            "sz.000403\n",
            "sz.000932\n",
            "sz.000999\n",
            "sz.001965\n",
            "sz.002335\n",
            "sz.002545\n",
            "sz.002558\n",
            "sz.002583\n",
            "sz.002588\n",
            "sz.002594\n",
            "sz.002634\n",
            "sz.002706\n",
            "sz.002721\n",
            "sz.002805\n",
            "sz.002912\n",
            "sz.002940\n",
            "sz.300192\n",
            "sz.300226\n",
            "sz.300246\n",
            "sz.300393\n",
            "sz.300421\n",
            "sz.300558\n",
            "sz.300572\n",
            "sz.300759\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbBeYEWfnzJf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "50f29491-46dc-46e6-ca92-92a22685449e"
      },
      "source": [
        "pp[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5.8331841e-07, 8.0780563e-07, 4.6011610e-03, 9.9539739e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8jQDq6fm-Sh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "62a684e4-d5f5-46e7-f651-c3d2b89c7a0a"
      },
      "source": [
        "for i in range(len(ts)):\n",
        "  if ts[i] == \"sh.600009\":\n",
        "     print(pp[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2.6273554e-08 1.2722618e-08 3.0374675e-04 9.9969625e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCP5NnXqsKAK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "121fea90-3759-4a3a-ffdd-00c52f538e08"
      },
      "source": [
        "# a = np.array(x[185:188])\n",
        "a =  pd.DataFrame(x[190].reshape(90,-1))\n",
        "print(a.shape)\n",
        "# print(x[187])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-174-714c304c87f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m190\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# print(x[187])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 344 into shape (90,newaxis)"
          ]
        }
      ]
    }
  ]
}